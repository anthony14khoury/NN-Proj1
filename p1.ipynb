{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthony.rahbany/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libpng16.7f72a3c5.so.16: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize with Mean and Standard Deviation\n",
    "])\n",
    "\n",
    "train_dataset = datasets.KMNIST('/blue/azare/anthony.rahbany/Data/Japanese_MNIST/', train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.KMNIST('/blue/azare/anthony.rahbany/Data/Japanese_MNIST/', train=False, download=False, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
    "val_size = len(train_dataset) - train_size   # 20% for validation\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class MediumMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MediumMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class LargeMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargeMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class ExtraLargeMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtraLargeMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class SuperLargeMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperLargeMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalution(model, dataloader, criterion, type=\"val\"):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    instance_count = 0\n",
    "    eval_correct_amount = 0\n",
    "\n",
    "    all_predictions, all_labels = [], []\n",
    "\n",
    "    for batch_id, (data, labels) in enumerate(dataloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "\n",
    "        eval_loss += criterion(outputs, labels)\n",
    "\n",
    "        # Compute Eval Accuracy\n",
    "        eval_predictions = torch.max(outputs.data, 1)[1]\n",
    "        eval_correct_amount += float((eval_predictions == labels.data).sum())\n",
    "        instance_count += len(labels)\n",
    "\n",
    "        all_predictions.extend(eval_predictions.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    avg_eval_acc = eval_correct_amount / instance_count\n",
    "    avg_eval_loss = eval_loss / instance_count\n",
    "\n",
    "    if type == \"test\":\n",
    "        return avg_eval_acc, avg_eval_loss, all_predictions, all_labels\n",
    "    \n",
    "    return avg_eval_acc, avg_eval_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    train_correct_amount = 0.0\n",
    "    instance_count = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        # Access the Data and Labels -> GPU\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Zero out the gradients for forward pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass - New Model Predictions\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Loss Calculation & Back Propagation\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute train Accuracy\n",
    "        train_predictions = torch.max(outputs.data, 1)[1]\n",
    "        train_correct_amount += float((train_predictions == labels.data).sum())\n",
    "        instance_count += len(labels)\n",
    "\n",
    "    avg_train_acc = train_correct_amount / instance_count\n",
    "    avg_train_loss = train_loss / instance_count\n",
    "\n",
    "    return avg_train_acc, avg_train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 | Train Loss: -108.32439 | Train Acc: 0.105 | Val Acc: 0.101\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -1720.26124 | Train Acc: 0.102 | Val Acc: 0.098\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -6877.01318 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -16658.30380 | Train Acc: 0.099 | Val Acc: 0.098\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -31650.60888 | Train Acc: 0.101 | Val Acc: 0.098\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -52330.97183 | Train Acc: 0.101 | Val Acc: 0.098\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -79131.03313 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -112574.94452 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -153023.74658 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -200871.86054 | Train Acc: 0.099 | Val Acc: 0.098\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -256579.32352 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -136096318.08796 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -1884608904.66133 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -7236687649.79200 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -17290950301.01333 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -32686250177.87733 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -53823690571.77600 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -81218888029.52533 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -115220472157.52533 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -156253084166.82666 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -205131111880.02133 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -261807644540.92801 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -807299348037.63196 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -3500806378968.40527 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -10001657452560.38477 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -21412005867596.45703 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -38382643544326.14062 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -61307857004047.01562 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -90669611510398.96875 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -126921108343838.03125 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -170586516833523.03125 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -221920597796454.40625 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -281382043013611.53125 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 422622538148.52264 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: 382536743780.35199 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: 348251801387.00800 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: 320410247277.22668 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: 291869275892.39465 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: 263066159611.90399 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: 238053497023.14667 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: 216390960130.73065 | Train Acc: 0.102 | Val Acc: 0.100\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: 193657675120.64001 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: 170367752776.36267 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: 147079939031.04001 | Train Acc: 0.102 | Val Acc: 0.098\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 19641868877.82400 | Train Acc: 0.098 | Val Acc: 0.101\n",
      "Saving Best Model. Test Accuracy: 0.1001\n",
      "Epoch: 1/1000 | Train Loss: 1993943318.52800 | Train Acc: 0.100 | Val Acc: 0.104\n",
      "Saving Best Model. Test Accuracy: 0.1001\n",
      "Epoch: 2/1000 | Train Loss: 1235814842.36800 | Train Acc: 0.099 | Val Acc: 0.098\n",
      "No Improvement: 1\n",
      "Epoch: 3/1000 | Train Loss: 1135076365.65333 | Train Acc: 0.102 | Val Acc: 0.101\n",
      "No Improvement: 2\n",
      "Epoch: 4/1000 | Train Loss: 1027703483.05067 | Train Acc: 0.102 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 5/1000 | Train Loss: 987140625.74933 | Train Acc: 0.102 | Val Acc: 0.102\n",
      "No Improvement: 4\n",
      "Epoch: 6/1000 | Train Loss: 1026901098.49600 | Train Acc: 0.102 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 7/1000 | Train Loss: 981850095.61600 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 8/1000 | Train Loss: 1006908265.81333 | Train Acc: 0.098 | Val Acc: 0.098\n",
      "No Improvement: 7\n",
      "Epoch: 9/1000 | Train Loss: 968498741.24800 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 8\n",
      "Epoch: 10/1000 | Train Loss: 1010908408.49067 | Train Acc: 0.097 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 11/1000 | Train Loss: 1046008976.72533 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 10804180762.62400 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: 8553837532.50133 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 2/1000 | Train Loss: 7342886584.32000 | Train Acc: 0.097 | Val Acc: 0.100\n",
      "No Improvement: 1\n",
      "Epoch: 3/1000 | Train Loss: 6828838701.73867 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 2\n",
      "Epoch: 4/1000 | Train Loss: 5844011141.80267 | Train Acc: 0.099 | Val Acc: 0.104\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 5/1000 | Train Loss: 5298269787.47733 | Train Acc: 0.101 | Val Acc: 0.099\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: 4793582245.20533 | Train Acc: 0.099 | Val Acc: 0.098\n",
      "No Improvement: 2\n",
      "Epoch: 7/1000 | Train Loss: 4134456536.40533 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 8/1000 | Train Loss: 3647948109.14133 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 4\n",
      "Epoch: 9/1000 | Train Loss: 3023298676.05333 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 10/1000 | Train Loss: 2597794537.47200 | Train Acc: 0.102 | Val Acc: 0.098\n",
      "No Improvement: 6\n",
      "Epoch: 11/1000 | Train Loss: 2164421659.30667 | Train Acc: 0.102 | Val Acc: 0.100\n",
      "No Improvement: 7\n",
      "Epoch: 12/1000 | Train Loss: 1730588919.12533 | Train Acc: 0.101 | Val Acc: 0.101\n",
      "No Improvement: 8\n",
      "Epoch: 13/1000 | Train Loss: 1427833279.82933 | Train Acc: 0.103 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 14/1000 | Train Loss: 1012654950.22933 | Train Acc: 0.100 | Val Acc: 0.098\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.06863 | Train Acc: 0.731 | Val Acc: 0.847\n",
      "Saving Best Model. Test Accuracy: 0.7051\n",
      "Epoch: 1/1000 | Train Loss: -0.17924 | Train Acc: 0.863 | Val Acc: 0.900\n",
      "Saving Best Model. Test Accuracy: 0.7749\n",
      "Epoch: 2/1000 | Train Loss: -0.31401 | Train Acc: 0.899 | Val Acc: 0.921\n",
      "Saving Best Model. Test Accuracy: 0.8109\n",
      "Epoch: 3/1000 | Train Loss: -0.47528 | Train Acc: 0.915 | Val Acc: 0.927\n",
      "Saving Best Model. Test Accuracy: 0.8211\n",
      "Epoch: 4/1000 | Train Loss: -0.66203 | Train Acc: 0.925 | Val Acc: 0.934\n",
      "Saving Best Model. Test Accuracy: 0.8392\n",
      "Epoch: 5/1000 | Train Loss: -0.87610 | Train Acc: 0.930 | Val Acc: 0.938\n",
      "Saving Best Model. Test Accuracy: 0.841\n",
      "Epoch: 6/1000 | Train Loss: -1.11521 | Train Acc: 0.931 | Val Acc: 0.934\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: -1.38124 | Train Acc: 0.930 | Val Acc: 0.929\n",
      "No Improvement: 2\n",
      "Epoch: 8/1000 | Train Loss: -1.67216 | Train Acc: 0.927 | Val Acc: 0.927\n",
      "No Improvement: 3\n",
      "Epoch: 9/1000 | Train Loss: -1.98820 | Train Acc: 0.923 | Val Acc: 0.915\n",
      "No Improvement: 4\n",
      "Epoch: 10/1000 | Train Loss: -2.33287 | Train Acc: 0.915 | Val Acc: 0.915\n",
      "No Improvement: 5\n",
      "Epoch: 11/1000 | Train Loss: -2.70445 | Train Acc: 0.909 | Val Acc: 0.904\n",
      "No Improvement: 6\n",
      "Epoch: 12/1000 | Train Loss: -3.09964 | Train Acc: 0.897 | Val Acc: 0.901\n",
      "No Improvement: 7\n",
      "Epoch: 13/1000 | Train Loss: -3.51547 | Train Acc: 0.885 | Val Acc: 0.878\n",
      "No Improvement: 8\n",
      "Epoch: 14/1000 | Train Loss: -3.96075 | Train Acc: 0.869 | Val Acc: 0.854\n",
      "No Improvement: 9\n",
      "Epoch: 15/1000 | Train Loss: -4.42775 | Train Acc: 0.848 | Val Acc: 0.837\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -111.65493 | Train Acc: 0.228 | Val Acc: 0.101\n",
      "Saving Best Model. Test Accuracy: 0.0966\n",
      "Epoch: 1/1000 | Train Loss: -705.89142 | Train Acc: 0.205 | Val Acc: 0.303\n",
      "Saving Best Model. Test Accuracy: 0.2201\n",
      "Epoch: 2/1000 | Train Loss: -1794.80247 | Train Acc: 0.298 | Val Acc: 0.317\n",
      "Saving Best Model. Test Accuracy: 0.2414\n",
      "Epoch: 3/1000 | Train Loss: -3288.73606 | Train Acc: 0.306 | Val Acc: 0.305\n",
      "No Improvement: 1\n",
      "Epoch: 4/1000 | Train Loss: -5131.48699 | Train Acc: 0.307 | Val Acc: 0.303\n",
      "No Improvement: 2\n",
      "Epoch: 5/1000 | Train Loss: -7286.24875 | Train Acc: 0.303 | Val Acc: 0.304\n",
      "No Improvement: 3\n",
      "Epoch: 6/1000 | Train Loss: -9746.97532 | Train Acc: 0.304 | Val Acc: 0.306\n",
      "No Improvement: 4\n",
      "Epoch: 7/1000 | Train Loss: -12477.40464 | Train Acc: 0.306 | Val Acc: 0.305\n",
      "No Improvement: 5\n",
      "Epoch: 8/1000 | Train Loss: -15502.84301 | Train Acc: 0.307 | Val Acc: 0.310\n",
      "No Improvement: 6\n",
      "Epoch: 9/1000 | Train Loss: -18779.38296 | Train Acc: 0.286 | Val Acc: 0.309\n",
      "No Improvement: 7\n",
      "Epoch: 10/1000 | Train Loss: -22363.97945 | Train Acc: 0.310 | Val Acc: 0.307\n",
      "No Improvement: 8\n",
      "Epoch: 11/1000 | Train Loss: -26186.99922 | Train Acc: 0.307 | Val Acc: 0.311\n",
      "No Improvement: 9\n",
      "Epoch: 12/1000 | Train Loss: -30281.50628 | Train Acc: 0.310 | Val Acc: 0.309\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -58231.39920 | Train Acc: 0.207 | Val Acc: 0.152\n",
      "Saving Best Model. Test Accuracy: 0.1306\n",
      "Epoch: 1/1000 | Train Loss: -139031.37510 | Train Acc: 0.176 | Val Acc: 0.215\n",
      "Saving Best Model. Test Accuracy: 0.1593\n",
      "Epoch: 2/1000 | Train Loss: -262856.03110 | Train Acc: 0.215 | Val Acc: 0.213\n",
      "No Improvement: 1\n",
      "Epoch: 3/1000 | Train Loss: -425970.62875 | Train Acc: 0.217 | Val Acc: 0.221\n",
      "Saving Best Model. Test Accuracy: 0.1577\n",
      "Epoch: 4/1000 | Train Loss: -623416.34350 | Train Acc: 0.185 | Val Acc: 0.224\n",
      "Saving Best Model. Test Accuracy: 0.165\n",
      "Epoch: 5/1000 | Train Loss: -852960.77625 | Train Acc: 0.206 | Val Acc: 0.159\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: -1112427.71767 | Train Acc: 0.165 | Val Acc: 0.156\n",
      "No Improvement: 2\n",
      "Epoch: 7/1000 | Train Loss: -1400074.03767 | Train Acc: 0.176 | Val Acc: 0.099\n",
      "No Improvement: 3\n",
      "Epoch: 8/1000 | Train Loss: -1716105.72333 | Train Acc: 0.160 | Val Acc: 0.099\n",
      "No Improvement: 4\n",
      "Epoch: 9/1000 | Train Loss: -2058161.27150 | Train Acc: 0.116 | Val Acc: 0.153\n",
      "No Improvement: 5\n",
      "Epoch: 10/1000 | Train Loss: -2428882.47333 | Train Acc: 0.157 | Val Acc: 0.155\n",
      "No Improvement: 6\n",
      "Epoch: 11/1000 | Train Loss: -2823675.35967 | Train Acc: 0.196 | Val Acc: 0.099\n",
      "No Improvement: 7\n",
      "Epoch: 12/1000 | Train Loss: -3248269.93967 | Train Acc: 0.122 | Val Acc: 0.099\n",
      "No Improvement: 8\n",
      "Epoch: 13/1000 | Train Loss: -3697359.27967 | Train Acc: 0.105 | Val Acc: 0.099\n",
      "No Improvement: 9\n",
      "Epoch: 14/1000 | Train Loss: -4172907.11400 | Train Acc: 0.145 | Val Acc: 0.099\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 20701.76583 | Train Acc: 0.101 | Val Acc: 0.099\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: 20224.68450 | Train Acc: 0.110 | Val Acc: 0.113\n",
      "Saving Best Model. Test Accuracy: 0.1068\n",
      "Epoch: 2/1000 | Train Loss: 19750.13474 | Train Acc: 0.133 | Val Acc: 0.152\n",
      "Saving Best Model. Test Accuracy: 0.1224\n",
      "Epoch: 3/1000 | Train Loss: 18894.25705 | Train Acc: 0.146 | Val Acc: 0.154\n",
      "Saving Best Model. Test Accuracy: 0.1236\n",
      "Epoch: 4/1000 | Train Loss: 17728.78914 | Train Acc: 0.152 | Val Acc: 0.153\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 17941.63806 | Train Acc: 0.165 | Val Acc: 0.158\n",
      "Saving Best Model. Test Accuracy: 0.1251\n",
      "Epoch: 6/1000 | Train Loss: 16936.03510 | Train Acc: 0.194 | Val Acc: 0.222\n",
      "Saving Best Model. Test Accuracy: 0.1623\n",
      "Epoch: 7/1000 | Train Loss: 16165.05284 | Train Acc: 0.209 | Val Acc: 0.222\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 15960.30698 | Train Acc: 0.213 | Val Acc: 0.224\n",
      "Saving Best Model. Test Accuracy: 0.168\n",
      "Epoch: 9/1000 | Train Loss: 15076.58164 | Train Acc: 0.216 | Val Acc: 0.221\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: 14572.93217 | Train Acc: 0.217 | Val Acc: 0.224\n",
      "No Improvement: 2\n",
      "Epoch: 11/1000 | Train Loss: 14325.43657 | Train Acc: 0.216 | Val Acc: 0.224\n",
      "No Improvement: 3\n",
      "Epoch: 12/1000 | Train Loss: 13792.89696 | Train Acc: 0.222 | Val Acc: 0.221\n",
      "No Improvement: 4\n",
      "Epoch: 13/1000 | Train Loss: 13819.37849 | Train Acc: 0.249 | Val Acc: 0.307\n",
      "Saving Best Model. Test Accuracy: 0.2403\n",
      "Epoch: 14/1000 | Train Loss: 13296.39229 | Train Acc: 0.272 | Val Acc: 0.311\n",
      "Saving Best Model. Test Accuracy: 0.2451\n",
      "Epoch: 15/1000 | Train Loss: 12814.71189 | Train Acc: 0.287 | Val Acc: 0.306\n",
      "No Improvement: 1\n",
      "Epoch: 16/1000 | Train Loss: 12845.73984 | Train Acc: 0.294 | Val Acc: 0.314\n",
      "Saving Best Model. Test Accuracy: 0.2501\n",
      "Epoch: 17/1000 | Train Loss: 12393.46808 | Train Acc: 0.303 | Val Acc: 0.312\n",
      "No Improvement: 1\n",
      "Epoch: 18/1000 | Train Loss: 12319.16126 | Train Acc: 0.305 | Val Acc: 0.312\n",
      "No Improvement: 2\n",
      "Epoch: 19/1000 | Train Loss: 12038.36364 | Train Acc: 0.304 | Val Acc: 0.309\n",
      "No Improvement: 3\n",
      "Epoch: 20/1000 | Train Loss: 11933.87796 | Train Acc: 0.307 | Val Acc: 0.312\n",
      "No Improvement: 4\n",
      "Epoch: 21/1000 | Train Loss: 11293.81778 | Train Acc: 0.307 | Val Acc: 0.311\n",
      "No Improvement: 5\n",
      "Epoch: 22/1000 | Train Loss: 11318.07654 | Train Acc: 0.315 | Val Acc: 0.312\n",
      "No Improvement: 6\n",
      "Epoch: 23/1000 | Train Loss: 10835.98742 | Train Acc: 0.326 | Val Acc: 0.316\n",
      "Saving Best Model. Test Accuracy: 0.2499\n",
      "Epoch: 24/1000 | Train Loss: 10699.55923 | Train Acc: 0.340 | Val Acc: 0.397\n",
      "Saving Best Model. Test Accuracy: 0.3093\n",
      "Epoch: 25/1000 | Train Loss: 10682.87128 | Train Acc: 0.359 | Val Acc: 0.403\n",
      "Saving Best Model. Test Accuracy: 0.3239\n",
      "Epoch: 26/1000 | Train Loss: 9878.06060 | Train Acc: 0.371 | Val Acc: 0.409\n",
      "Saving Best Model. Test Accuracy: 0.3311\n",
      "Epoch: 27/1000 | Train Loss: 9886.33176 | Train Acc: 0.380 | Val Acc: 0.407\n",
      "No Improvement: 1\n",
      "Epoch: 28/1000 | Train Loss: 9614.70577 | Train Acc: 0.387 | Val Acc: 0.408\n",
      "No Improvement: 2\n",
      "Epoch: 29/1000 | Train Loss: 9439.79517 | Train Acc: 0.397 | Val Acc: 0.406\n",
      "No Improvement: 3\n",
      "Epoch: 30/1000 | Train Loss: 9262.60049 | Train Acc: 0.411 | Val Acc: 0.409\n",
      "No Improvement: 4\n",
      "Epoch: 31/1000 | Train Loss: 8923.85701 | Train Acc: 0.434 | Val Acc: 0.422\n",
      "Saving Best Model. Test Accuracy: 0.351\n",
      "Epoch: 32/1000 | Train Loss: 8693.56597 | Train Acc: 0.454 | Val Acc: 0.499\n",
      "Saving Best Model. Test Accuracy: 0.408\n",
      "Epoch: 33/1000 | Train Loss: 8657.83200 | Train Acc: 0.465 | Val Acc: 0.500\n",
      "Saving Best Model. Test Accuracy: 0.4097\n",
      "Epoch: 34/1000 | Train Loss: 8599.52414 | Train Acc: 0.474 | Val Acc: 0.502\n",
      "Saving Best Model. Test Accuracy: 0.4142\n",
      "Epoch: 35/1000 | Train Loss: 8189.62154 | Train Acc: 0.481 | Val Acc: 0.503\n",
      "Saving Best Model. Test Accuracy: 0.4158\n",
      "Epoch: 36/1000 | Train Loss: 7876.17149 | Train Acc: 0.488 | Val Acc: 0.503\n",
      "No Improvement: 1\n",
      "Epoch: 37/1000 | Train Loss: 7881.85462 | Train Acc: 0.492 | Val Acc: 0.504\n",
      "Saving Best Model. Test Accuracy: 0.4157\n",
      "Epoch: 38/1000 | Train Loss: 7372.84665 | Train Acc: 0.501 | Val Acc: 0.507\n",
      "Saving Best Model. Test Accuracy: 0.4235\n",
      "Epoch: 39/1000 | Train Loss: 7498.77709 | Train Acc: 0.504 | Val Acc: 0.505\n",
      "No Improvement: 1\n",
      "Epoch: 40/1000 | Train Loss: 7168.48020 | Train Acc: 0.503 | Val Acc: 0.508\n",
      "Saving Best Model. Test Accuracy: 0.4257\n",
      "Epoch: 41/1000 | Train Loss: 7006.50526 | Train Acc: 0.508 | Val Acc: 0.509\n",
      "Saving Best Model. Test Accuracy: 0.4239\n",
      "Epoch: 42/1000 | Train Loss: 6875.92583 | Train Acc: 0.508 | Val Acc: 0.511\n",
      "Saving Best Model. Test Accuracy: 0.4308\n",
      "Epoch: 43/1000 | Train Loss: 6633.96136 | Train Acc: 0.511 | Val Acc: 0.509\n",
      "No Improvement: 1\n",
      "Epoch: 44/1000 | Train Loss: 6516.39818 | Train Acc: 0.509 | Val Acc: 0.515\n",
      "Saving Best Model. Test Accuracy: 0.4347\n",
      "Epoch: 45/1000 | Train Loss: 6907.97244 | Train Acc: 0.507 | Val Acc: 0.514\n",
      "No Improvement: 1\n",
      "Epoch: 46/1000 | Train Loss: 6421.00101 | Train Acc: 0.507 | Val Acc: 0.512\n",
      "No Improvement: 2\n",
      "Epoch: 47/1000 | Train Loss: 6367.51085 | Train Acc: 0.511 | Val Acc: 0.516\n",
      "Saving Best Model. Test Accuracy: 0.4432\n",
      "Epoch: 48/1000 | Train Loss: 6399.29942 | Train Acc: 0.510 | Val Acc: 0.524\n",
      "Saving Best Model. Test Accuracy: 0.4507\n",
      "Epoch: 49/1000 | Train Loss: 6262.68889 | Train Acc: 0.515 | Val Acc: 0.520\n",
      "No Improvement: 1\n",
      "Epoch: 50/1000 | Train Loss: 6320.39276 | Train Acc: 0.514 | Val Acc: 0.519\n",
      "No Improvement: 2\n",
      "Epoch: 51/1000 | Train Loss: 5931.24947 | Train Acc: 0.521 | Val Acc: 0.526\n",
      "Saving Best Model. Test Accuracy: 0.457\n",
      "Epoch: 52/1000 | Train Loss: 6118.23522 | Train Acc: 0.519 | Val Acc: 0.527\n",
      "Saving Best Model. Test Accuracy: 0.4581\n",
      "Epoch: 53/1000 | Train Loss: 6051.24608 | Train Acc: 0.521 | Val Acc: 0.530\n",
      "Saving Best Model. Test Accuracy: 0.4639\n",
      "Epoch: 54/1000 | Train Loss: 5672.42898 | Train Acc: 0.524 | Val Acc: 0.532\n",
      "Saving Best Model. Test Accuracy: 0.4652\n",
      "Epoch: 55/1000 | Train Loss: 5815.24203 | Train Acc: 0.522 | Val Acc: 0.524\n",
      "No Improvement: 1\n",
      "Epoch: 56/1000 | Train Loss: 5824.41742 | Train Acc: 0.529 | Val Acc: 0.528\n",
      "No Improvement: 2\n",
      "Epoch: 57/1000 | Train Loss: 5864.90919 | Train Acc: 0.527 | Val Acc: 0.536\n",
      "Saving Best Model. Test Accuracy: 0.4703\n",
      "Epoch: 58/1000 | Train Loss: 5673.20209 | Train Acc: 0.525 | Val Acc: 0.539\n",
      "Saving Best Model. Test Accuracy: 0.4825\n",
      "Epoch: 59/1000 | Train Loss: 5643.22947 | Train Acc: 0.527 | Val Acc: 0.532\n",
      "No Improvement: 1\n",
      "Epoch: 60/1000 | Train Loss: 5526.76177 | Train Acc: 0.528 | Val Acc: 0.535\n",
      "No Improvement: 2\n",
      "Epoch: 61/1000 | Train Loss: 5659.46400 | Train Acc: 0.529 | Val Acc: 0.541\n",
      "Saving Best Model. Test Accuracy: 0.4837\n",
      "Epoch: 62/1000 | Train Loss: 5539.07825 | Train Acc: 0.530 | Val Acc: 0.543\n",
      "Saving Best Model. Test Accuracy: 0.487\n",
      "Epoch: 63/1000 | Train Loss: 5281.09601 | Train Acc: 0.532 | Val Acc: 0.539\n",
      "No Improvement: 1\n",
      "Epoch: 64/1000 | Train Loss: 5448.30582 | Train Acc: 0.534 | Val Acc: 0.542\n",
      "No Improvement: 2\n",
      "Epoch: 65/1000 | Train Loss: 5160.18571 | Train Acc: 0.535 | Val Acc: 0.548\n",
      "Saving Best Model. Test Accuracy: 0.4926\n",
      "Epoch: 66/1000 | Train Loss: 5229.99963 | Train Acc: 0.535 | Val Acc: 0.544\n",
      "No Improvement: 1\n",
      "Epoch: 67/1000 | Train Loss: 5340.95432 | Train Acc: 0.534 | Val Acc: 0.548\n",
      "No Improvement: 2\n",
      "Epoch: 68/1000 | Train Loss: 5036.08153 | Train Acc: 0.533 | Val Acc: 0.549\n",
      "Saving Best Model. Test Accuracy: 0.4961\n",
      "Epoch: 69/1000 | Train Loss: 5156.14646 | Train Acc: 0.534 | Val Acc: 0.543\n",
      "No Improvement: 1\n",
      "Epoch: 70/1000 | Train Loss: 4959.18789 | Train Acc: 0.540 | Val Acc: 0.552\n",
      "Saving Best Model. Test Accuracy: 0.5002\n",
      "Epoch: 71/1000 | Train Loss: 5155.13609 | Train Acc: 0.538 | Val Acc: 0.554\n",
      "Saving Best Model. Test Accuracy: 0.5032\n",
      "Epoch: 72/1000 | Train Loss: 5000.01565 | Train Acc: 0.538 | Val Acc: 0.548\n",
      "No Improvement: 1\n",
      "Epoch: 73/1000 | Train Loss: 4953.98017 | Train Acc: 0.538 | Val Acc: 0.553\n",
      "No Improvement: 2\n",
      "Epoch: 74/1000 | Train Loss: 4969.60137 | Train Acc: 0.535 | Val Acc: 0.550\n",
      "No Improvement: 3\n",
      "Epoch: 75/1000 | Train Loss: 5064.39311 | Train Acc: 0.542 | Val Acc: 0.555\n",
      "Saving Best Model. Test Accuracy: 0.5048\n",
      "Epoch: 76/1000 | Train Loss: 4761.97037 | Train Acc: 0.542 | Val Acc: 0.552\n",
      "No Improvement: 1\n",
      "Epoch: 77/1000 | Train Loss: 4942.47598 | Train Acc: 0.541 | Val Acc: 0.553\n",
      "No Improvement: 2\n",
      "Epoch: 78/1000 | Train Loss: 4877.84024 | Train Acc: 0.542 | Val Acc: 0.553\n",
      "No Improvement: 3\n",
      "Epoch: 79/1000 | Train Loss: 4579.64282 | Train Acc: 0.539 | Val Acc: 0.558\n",
      "Saving Best Model. Test Accuracy: 0.508\n",
      "Epoch: 80/1000 | Train Loss: 4891.64822 | Train Acc: 0.541 | Val Acc: 0.557\n",
      "No Improvement: 1\n",
      "Epoch: 81/1000 | Train Loss: 4845.97568 | Train Acc: 0.544 | Val Acc: 0.559\n",
      "Saving Best Model. Test Accuracy: 0.5105\n",
      "Epoch: 82/1000 | Train Loss: 4769.94651 | Train Acc: 0.541 | Val Acc: 0.557\n",
      "No Improvement: 1\n",
      "Epoch: 83/1000 | Train Loss: 4693.18665 | Train Acc: 0.540 | Val Acc: 0.558\n",
      "No Improvement: 2\n",
      "Epoch: 84/1000 | Train Loss: 4622.81977 | Train Acc: 0.542 | Val Acc: 0.557\n",
      "No Improvement: 3\n",
      "Epoch: 85/1000 | Train Loss: 4645.51807 | Train Acc: 0.547 | Val Acc: 0.552\n",
      "No Improvement: 4\n",
      "Epoch: 86/1000 | Train Loss: 4521.94064 | Train Acc: 0.546 | Val Acc: 0.560\n",
      "Saving Best Model. Test Accuracy: 0.5115\n",
      "Epoch: 87/1000 | Train Loss: 4548.80288 | Train Acc: 0.544 | Val Acc: 0.558\n",
      "No Improvement: 1\n",
      "Epoch: 88/1000 | Train Loss: 4590.02629 | Train Acc: 0.545 | Val Acc: 0.564\n",
      "Saving Best Model. Test Accuracy: 0.5212\n",
      "Epoch: 89/1000 | Train Loss: 4670.34307 | Train Acc: 0.546 | Val Acc: 0.561\n",
      "No Improvement: 1\n",
      "Epoch: 90/1000 | Train Loss: 4672.37871 | Train Acc: 0.545 | Val Acc: 0.560\n",
      "No Improvement: 2\n",
      "Epoch: 91/1000 | Train Loss: 4442.93680 | Train Acc: 0.545 | Val Acc: 0.560\n",
      "No Improvement: 3\n",
      "Epoch: 92/1000 | Train Loss: 4476.53256 | Train Acc: 0.545 | Val Acc: 0.557\n",
      "No Improvement: 4\n",
      "Epoch: 93/1000 | Train Loss: 4432.48245 | Train Acc: 0.545 | Val Acc: 0.553\n",
      "No Improvement: 5\n",
      "Epoch: 94/1000 | Train Loss: 4379.69765 | Train Acc: 0.546 | Val Acc: 0.566\n",
      "Saving Best Model. Test Accuracy: 0.5212\n",
      "Epoch: 95/1000 | Train Loss: 4366.10653 | Train Acc: 0.548 | Val Acc: 0.566\n",
      "No Improvement: 1\n",
      "Epoch: 96/1000 | Train Loss: 4672.03144 | Train Acc: 0.548 | Val Acc: 0.562\n",
      "No Improvement: 2\n",
      "Epoch: 97/1000 | Train Loss: 4306.40415 | Train Acc: 0.548 | Val Acc: 0.563\n",
      "No Improvement: 3\n",
      "Epoch: 98/1000 | Train Loss: 4318.33389 | Train Acc: 0.545 | Val Acc: 0.564\n",
      "No Improvement: 4\n",
      "Epoch: 99/1000 | Train Loss: 4653.71747 | Train Acc: 0.543 | Val Acc: 0.563\n",
      "No Improvement: 5\n",
      "Epoch: 100/1000 | Train Loss: 4416.35183 | Train Acc: 0.549 | Val Acc: 0.560\n",
      "No Improvement: 6\n",
      "Epoch: 101/1000 | Train Loss: 4286.41735 | Train Acc: 0.549 | Val Acc: 0.564\n",
      "No Improvement: 7\n",
      "Epoch: 102/1000 | Train Loss: 4318.97995 | Train Acc: 0.551 | Val Acc: 0.564\n",
      "No Improvement: 8\n",
      "Epoch: 103/1000 | Train Loss: 4309.09603 | Train Acc: 0.548 | Val Acc: 0.562\n",
      "No Improvement: 9\n",
      "Epoch: 104/1000 | Train Loss: 4332.77073 | Train Acc: 0.549 | Val Acc: 0.562\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 3884.95048 | Train Acc: 0.558 | Val Acc: 0.567\n",
      "Saving Best Model. Test Accuracy: 0.519\n",
      "Epoch: 1/1000 | Train Loss: 2920.30064 | Train Acc: 0.564 | Val Acc: 0.571\n",
      "Saving Best Model. Test Accuracy: 0.5302\n",
      "Epoch: 2/1000 | Train Loss: 2391.69111 | Train Acc: 0.567 | Val Acc: 0.572\n",
      "Saving Best Model. Test Accuracy: 0.5256\n",
      "Epoch: 3/1000 | Train Loss: 2087.32912 | Train Acc: 0.568 | Val Acc: 0.577\n",
      "Saving Best Model. Test Accuracy: 0.5427\n",
      "Epoch: 4/1000 | Train Loss: 2028.58202 | Train Acc: 0.568 | Val Acc: 0.569\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 1610.32363 | Train Acc: 0.567 | Val Acc: 0.577\n",
      "No Improvement: 2\n",
      "Epoch: 6/1000 | Train Loss: 1589.44842 | Train Acc: 0.568 | Val Acc: 0.575\n",
      "No Improvement: 3\n",
      "Epoch: 7/1000 | Train Loss: 1313.22654 | Train Acc: 0.568 | Val Acc: 0.584\n",
      "Saving Best Model. Test Accuracy: 0.5548\n",
      "Epoch: 8/1000 | Train Loss: 1277.30486 | Train Acc: 0.569 | Val Acc: 0.569\n",
      "No Improvement: 1\n",
      "Epoch: 9/1000 | Train Loss: 1128.98537 | Train Acc: 0.567 | Val Acc: 0.577\n",
      "No Improvement: 2\n",
      "Epoch: 10/1000 | Train Loss: 1095.82001 | Train Acc: 0.568 | Val Acc: 0.594\n",
      "Saving Best Model. Test Accuracy: 0.5645\n",
      "Epoch: 11/1000 | Train Loss: 1004.06866 | Train Acc: 0.572 | Val Acc: 0.586\n",
      "No Improvement: 1\n",
      "Epoch: 12/1000 | Train Loss: 924.52724 | Train Acc: 0.572 | Val Acc: 0.572\n",
      "No Improvement: 2\n",
      "Epoch: 13/1000 | Train Loss: 804.75730 | Train Acc: 0.571 | Val Acc: 0.574\n",
      "No Improvement: 3\n",
      "Epoch: 14/1000 | Train Loss: 732.40019 | Train Acc: 0.571 | Val Acc: 0.584\n",
      "No Improvement: 4\n",
      "Epoch: 15/1000 | Train Loss: 730.11789 | Train Acc: 0.572 | Val Acc: 0.575\n",
      "No Improvement: 5\n",
      "Epoch: 16/1000 | Train Loss: 690.44786 | Train Acc: 0.574 | Val Acc: 0.573\n",
      "No Improvement: 6\n",
      "Epoch: 17/1000 | Train Loss: 643.02422 | Train Acc: 0.575 | Val Acc: 0.581\n",
      "No Improvement: 7\n",
      "Epoch: 18/1000 | Train Loss: 608.74126 | Train Acc: 0.575 | Val Acc: 0.584\n",
      "No Improvement: 8\n",
      "Epoch: 19/1000 | Train Loss: 530.71090 | Train Acc: 0.574 | Val Acc: 0.572\n",
      "No Improvement: 9\n",
      "Epoch: 20/1000 | Train Loss: 486.31059 | Train Acc: 0.576 | Val Acc: 0.604\n",
      "Saving Best Model. Test Accuracy: 0.5691\n",
      "Epoch: 21/1000 | Train Loss: 524.49023 | Train Acc: 0.575 | Val Acc: 0.584\n",
      "No Improvement: 1\n",
      "Epoch: 22/1000 | Train Loss: 493.02585 | Train Acc: 0.576 | Val Acc: 0.573\n",
      "No Improvement: 2\n",
      "Epoch: 23/1000 | Train Loss: 430.56623 | Train Acc: 0.578 | Val Acc: 0.576\n",
      "No Improvement: 3\n",
      "Epoch: 24/1000 | Train Loss: 421.86857 | Train Acc: 0.578 | Val Acc: 0.575\n",
      "No Improvement: 4\n",
      "Epoch: 25/1000 | Train Loss: 431.68863 | Train Acc: 0.575 | Val Acc: 0.573\n",
      "No Improvement: 5\n",
      "Epoch: 26/1000 | Train Loss: 409.82074 | Train Acc: 0.579 | Val Acc: 0.605\n",
      "Saving Best Model. Test Accuracy: 0.5713\n",
      "Epoch: 27/1000 | Train Loss: 372.08458 | Train Acc: 0.581 | Val Acc: 0.591\n",
      "No Improvement: 1\n",
      "Epoch: 28/1000 | Train Loss: 397.57249 | Train Acc: 0.579 | Val Acc: 0.573\n",
      "No Improvement: 2\n",
      "Epoch: 29/1000 | Train Loss: 312.61764 | Train Acc: 0.579 | Val Acc: 0.588\n",
      "No Improvement: 3\n",
      "Epoch: 30/1000 | Train Loss: 307.04788 | Train Acc: 0.581 | Val Acc: 0.569\n",
      "No Improvement: 4\n",
      "Epoch: 31/1000 | Train Loss: 307.15787 | Train Acc: 0.576 | Val Acc: 0.592\n",
      "No Improvement: 5\n",
      "Epoch: 32/1000 | Train Loss: 276.34428 | Train Acc: 0.580 | Val Acc: 0.573\n",
      "No Improvement: 6\n",
      "Epoch: 33/1000 | Train Loss: 268.97781 | Train Acc: 0.577 | Val Acc: 0.611\n",
      "Saving Best Model. Test Accuracy: 0.5708\n",
      "Epoch: 34/1000 | Train Loss: 255.90987 | Train Acc: 0.577 | Val Acc: 0.580\n",
      "No Improvement: 1\n",
      "Epoch: 35/1000 | Train Loss: 263.53813 | Train Acc: 0.579 | Val Acc: 0.594\n",
      "No Improvement: 2\n",
      "Epoch: 36/1000 | Train Loss: 219.24951 | Train Acc: 0.579 | Val Acc: 0.573\n",
      "No Improvement: 3\n",
      "Epoch: 37/1000 | Train Loss: 254.11749 | Train Acc: 0.577 | Val Acc: 0.578\n",
      "No Improvement: 4\n",
      "Epoch: 38/1000 | Train Loss: 202.75073 | Train Acc: 0.576 | Val Acc: 0.574\n",
      "No Improvement: 5\n",
      "Epoch: 39/1000 | Train Loss: 230.56777 | Train Acc: 0.579 | Val Acc: 0.580\n",
      "No Improvement: 6\n",
      "Epoch: 40/1000 | Train Loss: 181.63943 | Train Acc: 0.578 | Val Acc: 0.579\n",
      "No Improvement: 7\n",
      "Epoch: 41/1000 | Train Loss: 181.68294 | Train Acc: 0.578 | Val Acc: 0.600\n",
      "No Improvement: 8\n",
      "Epoch: 42/1000 | Train Loss: 228.62648 | Train Acc: 0.579 | Val Acc: 0.583\n",
      "No Improvement: 9\n",
      "Epoch: 43/1000 | Train Loss: 194.40483 | Train Acc: 0.579 | Val Acc: 0.585\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 743.63060 | Train Acc: 0.573 | Val Acc: 0.611\n",
      "Saving Best Model. Test Accuracy: 0.56\n",
      "Epoch: 1/1000 | Train Loss: 612.05899 | Train Acc: 0.568 | Val Acc: 0.599\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: 305.14267 | Train Acc: 0.566 | Val Acc: 0.582\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: 380.54415 | Train Acc: 0.564 | Val Acc: 0.590\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: 371.28282 | Train Acc: 0.559 | Val Acc: 0.578\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: 323.83693 | Train Acc: 0.559 | Val Acc: 0.611\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: 199.74140 | Train Acc: 0.558 | Val Acc: 0.623\n",
      "Saving Best Model. Test Accuracy: 0.5661\n",
      "Epoch: 7/1000 | Train Loss: 185.27126 | Train Acc: 0.557 | Val Acc: 0.590\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 203.03975 | Train Acc: 0.558 | Val Acc: 0.580\n",
      "No Improvement: 2\n",
      "Epoch: 9/1000 | Train Loss: 153.97276 | Train Acc: 0.548 | Val Acc: 0.636\n",
      "Saving Best Model. Test Accuracy: 0.5751\n",
      "Epoch: 10/1000 | Train Loss: 195.03735 | Train Acc: 0.547 | Val Acc: 0.608\n",
      "No Improvement: 1\n",
      "Epoch: 11/1000 | Train Loss: 223.61446 | Train Acc: 0.543 | Val Acc: 0.601\n",
      "No Improvement: 2\n",
      "Epoch: 12/1000 | Train Loss: 166.12603 | Train Acc: 0.533 | Val Acc: 0.560\n",
      "No Improvement: 3\n",
      "Epoch: 13/1000 | Train Loss: 153.37179 | Train Acc: 0.530 | Val Acc: 0.550\n",
      "No Improvement: 4\n",
      "Epoch: 14/1000 | Train Loss: 174.19271 | Train Acc: 0.519 | Val Acc: 0.587\n",
      "No Improvement: 5\n",
      "Epoch: 15/1000 | Train Loss: 149.62519 | Train Acc: 0.518 | Val Acc: 0.542\n",
      "No Improvement: 6\n",
      "Epoch: 16/1000 | Train Loss: 85.17182 | Train Acc: 0.521 | Val Acc: 0.556\n",
      "No Improvement: 7\n",
      "Epoch: 17/1000 | Train Loss: 143.25667 | Train Acc: 0.525 | Val Acc: 0.616\n",
      "No Improvement: 8\n",
      "Epoch: 18/1000 | Train Loss: 172.08853 | Train Acc: 0.520 | Val Acc: 0.579\n",
      "No Improvement: 9\n",
      "Epoch: 19/1000 | Train Loss: 152.43126 | Train Acc: 0.516 | Val Acc: 0.521\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.06998 | Train Acc: 0.708 | Val Acc: 0.865\n",
      "Saving Best Model. Test Accuracy: 0.7265\n",
      "Epoch: 1/1000 | Train Loss: -0.18601 | Train Acc: 0.876 | Val Acc: 0.911\n",
      "Saving Best Model. Test Accuracy: 0.804\n",
      "Epoch: 2/1000 | Train Loss: -0.32470 | Train Acc: 0.912 | Val Acc: 0.937\n",
      "Saving Best Model. Test Accuracy: 0.8458\n",
      "Epoch: 3/1000 | Train Loss: -0.48930 | Train Acc: 0.930 | Val Acc: 0.944\n",
      "Saving Best Model. Test Accuracy: 0.8587\n",
      "Epoch: 4/1000 | Train Loss: -0.67800 | Train Acc: 0.939 | Val Acc: 0.950\n",
      "Saving Best Model. Test Accuracy: 0.8686\n",
      "Epoch: 5/1000 | Train Loss: -0.89051 | Train Acc: 0.946 | Val Acc: 0.950\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: -1.12572 | Train Acc: 0.949 | Val Acc: 0.954\n",
      "Saving Best Model. Test Accuracy: 0.8764\n",
      "Epoch: 7/1000 | Train Loss: -1.38376 | Train Acc: 0.955 | Val Acc: 0.953\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: -1.66316 | Train Acc: 0.956 | Val Acc: 0.955\n",
      "Saving Best Model. Test Accuracy: 0.8794\n",
      "Epoch: 9/1000 | Train Loss: -1.96620 | Train Acc: 0.956 | Val Acc: 0.954\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: -2.29428 | Train Acc: 0.956 | Val Acc: 0.950\n",
      "No Improvement: 2\n",
      "Epoch: 11/1000 | Train Loss: -2.64443 | Train Acc: 0.954 | Val Acc: 0.956\n",
      "Saving Best Model. Test Accuracy: 0.8789\n",
      "Epoch: 12/1000 | Train Loss: -3.02183 | Train Acc: 0.952 | Val Acc: 0.950\n",
      "No Improvement: 1\n",
      "Epoch: 13/1000 | Train Loss: -3.42159 | Train Acc: 0.948 | Val Acc: 0.958\n",
      "Saving Best Model. Test Accuracy: 0.884\n",
      "Epoch: 14/1000 | Train Loss: -3.84811 | Train Acc: 0.942 | Val Acc: 0.950\n",
      "No Improvement: 1\n",
      "Epoch: 15/1000 | Train Loss: -4.29163 | Train Acc: 0.940 | Val Acc: 0.939\n",
      "No Improvement: 2\n",
      "Epoch: 16/1000 | Train Loss: -4.76683 | Train Acc: 0.932 | Val Acc: 0.940\n",
      "No Improvement: 3\n",
      "Epoch: 17/1000 | Train Loss: -5.25890 | Train Acc: 0.923 | Val Acc: 0.947\n",
      "No Improvement: 4\n",
      "Epoch: 18/1000 | Train Loss: -5.76726 | Train Acc: 0.914 | Val Acc: 0.916\n",
      "No Improvement: 5\n",
      "Epoch: 19/1000 | Train Loss: -6.31595 | Train Acc: 0.900 | Val Acc: 0.888\n",
      "No Improvement: 6\n",
      "Epoch: 20/1000 | Train Loss: -6.87688 | Train Acc: 0.885 | Val Acc: 0.852\n",
      "No Improvement: 7\n",
      "Epoch: 21/1000 | Train Loss: -7.46568 | Train Acc: 0.873 | Val Acc: 0.849\n",
      "No Improvement: 8\n",
      "Epoch: 22/1000 | Train Loss: -8.08181 | Train Acc: 0.869 | Val Acc: 0.846\n",
      "No Improvement: 9\n",
      "Epoch: 23/1000 | Train Loss: -8.71806 | Train Acc: 0.865 | Val Acc: 0.850\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -118.01867 | Train Acc: 0.381 | Val Acc: 0.230\n",
      "Saving Best Model. Test Accuracy: 0.1868\n",
      "Epoch: 1/1000 | Train Loss: -702.19748 | Train Acc: 0.125 | Val Acc: 0.185\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -1772.21114 | Train Acc: 0.169 | Val Acc: 0.189\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -3238.60834 | Train Acc: 0.185 | Val Acc: 0.189\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -5049.96148 | Train Acc: 0.187 | Val Acc: 0.190\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -7167.79554 | Train Acc: 0.188 | Val Acc: 0.192\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -9579.75687 | Train Acc: 0.190 | Val Acc: 0.191\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -12276.71667 | Train Acc: 0.190 | Val Acc: 0.192\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -15239.10391 | Train Acc: 0.191 | Val Acc: 0.192\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -18482.57298 | Train Acc: 0.191 | Val Acc: 0.193\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -21981.03550 | Train Acc: 0.191 | Val Acc: 0.193\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -46597.82309 | Train Acc: 0.159 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -121367.92773 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -239161.45131 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -395424.68458 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -586121.97267 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -808327.93325 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -1059413.73283 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -1338144.81850 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -1645539.94550 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -1978638.25317 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -2337433.02367 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 16111.16982 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: 15282.87874 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: 14987.62488 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: 14560.81225 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: 13822.16560 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: 13292.17168 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: 12827.82463 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: 12390.55422 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: 12104.50135 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: 11452.37052 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: 11356.16590 | Train Acc: 0.101 | Val Acc: 0.100\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 4265.03366 | Train Acc: 0.456 | Val Acc: 0.572\n",
      "Saving Best Model. Test Accuracy: 0.5486\n",
      "Epoch: 1/1000 | Train Loss: 2201.91319 | Train Acc: 0.564 | Val Acc: 0.576\n",
      "Saving Best Model. Test Accuracy: 0.5521\n",
      "Epoch: 2/1000 | Train Loss: 1785.51233 | Train Acc: 0.563 | Val Acc: 0.582\n",
      "Saving Best Model. Test Accuracy: 0.5622\n",
      "Epoch: 3/1000 | Train Loss: 1404.31146 | Train Acc: 0.564 | Val Acc: 0.581\n",
      "No Improvement: 1\n",
      "Epoch: 4/1000 | Train Loss: 1215.10601 | Train Acc: 0.562 | Val Acc: 0.586\n",
      "Saving Best Model. Test Accuracy: 0.5665\n",
      "Epoch: 5/1000 | Train Loss: 1036.92285 | Train Acc: 0.565 | Val Acc: 0.581\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: 908.50469 | Train Acc: 0.561 | Val Acc: 0.573\n",
      "No Improvement: 2\n",
      "Epoch: 7/1000 | Train Loss: 860.94655 | Train Acc: 0.564 | Val Acc: 0.576\n",
      "No Improvement: 3\n",
      "Epoch: 8/1000 | Train Loss: 761.46946 | Train Acc: 0.564 | Val Acc: 0.574\n",
      "No Improvement: 4\n",
      "Epoch: 9/1000 | Train Loss: 682.31992 | Train Acc: 0.564 | Val Acc: 0.576\n",
      "No Improvement: 5\n",
      "Epoch: 10/1000 | Train Loss: 537.14446 | Train Acc: 0.563 | Val Acc: 0.587\n",
      "Saving Best Model. Test Accuracy: 0.5563\n",
      "Epoch: 11/1000 | Train Loss: 551.16420 | Train Acc: 0.565 | Val Acc: 0.584\n",
      "No Improvement: 1\n",
      "Epoch: 12/1000 | Train Loss: 557.46829 | Train Acc: 0.563 | Val Acc: 0.577\n",
      "No Improvement: 2\n",
      "Epoch: 13/1000 | Train Loss: 473.25629 | Train Acc: 0.567 | Val Acc: 0.581\n",
      "No Improvement: 3\n",
      "Epoch: 14/1000 | Train Loss: 530.08624 | Train Acc: 0.562 | Val Acc: 0.586\n",
      "No Improvement: 4\n",
      "Epoch: 15/1000 | Train Loss: 470.94379 | Train Acc: 0.559 | Val Acc: 0.577\n",
      "No Improvement: 5\n",
      "Epoch: 16/1000 | Train Loss: 439.32421 | Train Acc: 0.562 | Val Acc: 0.576\n",
      "No Improvement: 6\n",
      "Epoch: 17/1000 | Train Loss: 416.46614 | Train Acc: 0.566 | Val Acc: 0.578\n",
      "No Improvement: 7\n",
      "Epoch: 18/1000 | Train Loss: 368.52344 | Train Acc: 0.564 | Val Acc: 0.589\n",
      "Saving Best Model. Test Accuracy: 0.552\n",
      "Epoch: 19/1000 | Train Loss: 342.39313 | Train Acc: 0.562 | Val Acc: 0.577\n",
      "No Improvement: 1\n",
      "Epoch: 20/1000 | Train Loss: 403.67282 | Train Acc: 0.559 | Val Acc: 0.579\n",
      "No Improvement: 2\n",
      "Epoch: 21/1000 | Train Loss: 287.50718 | Train Acc: 0.563 | Val Acc: 0.576\n",
      "No Improvement: 3\n",
      "Epoch: 22/1000 | Train Loss: 346.62000 | Train Acc: 0.562 | Val Acc: 0.569\n",
      "No Improvement: 4\n",
      "Epoch: 23/1000 | Train Loss: 292.75787 | Train Acc: 0.562 | Val Acc: 0.576\n",
      "No Improvement: 5\n",
      "Epoch: 24/1000 | Train Loss: 312.81615 | Train Acc: 0.560 | Val Acc: 0.575\n",
      "No Improvement: 6\n",
      "Epoch: 25/1000 | Train Loss: 290.31004 | Train Acc: 0.562 | Val Acc: 0.579\n",
      "No Improvement: 7\n",
      "Epoch: 26/1000 | Train Loss: 284.41755 | Train Acc: 0.561 | Val Acc: 0.573\n",
      "No Improvement: 8\n",
      "Epoch: 27/1000 | Train Loss: 284.30893 | Train Acc: 0.563 | Val Acc: 0.587\n",
      "No Improvement: 9\n",
      "Epoch: 28/1000 | Train Loss: 233.60320 | Train Acc: 0.563 | Val Acc: 0.581\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 698.92864 | Train Acc: 0.553 | Val Acc: 0.607\n",
      "Saving Best Model. Test Accuracy: 0.5539\n",
      "Epoch: 1/1000 | Train Loss: 681.18400 | Train Acc: 0.552 | Val Acc: 0.567\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: 498.00799 | Train Acc: 0.549 | Val Acc: 0.502\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: 517.40120 | Train Acc: 0.543 | Val Acc: 0.593\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: 334.52575 | Train Acc: 0.544 | Val Acc: 0.584\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: 226.18344 | Train Acc: 0.535 | Val Acc: 0.531\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: 178.26994 | Train Acc: 0.538 | Val Acc: 0.573\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: 271.42272 | Train Acc: 0.535 | Val Acc: 0.588\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: 218.80842 | Train Acc: 0.523 | Val Acc: 0.564\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: 158.15714 | Train Acc: 0.520 | Val Acc: 0.592\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: 112.06860 | Train Acc: 0.526 | Val Acc: 0.514\n",
      "No Improvement: 10\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "patience = 10\n",
    "\n",
    "models = [SmallMLP(), MediumMLP(), LargeMLP()]\n",
    "model_names = [\"small\", \"medium\", \"large\"]\n",
    "learning_rates = [0.0001, 0.01, 0.1]\n",
    "loss_functions = [nn.NLLLoss(), nn.CrossEntropyLoss()]\n",
    "loss_fn_names = ['nll', 'ce']\n",
    "\n",
    "\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for loss_fn, loss_fn_name in zip(loss_functions, loss_fn_names):\n",
    "        for lr in learning_rates:\n",
    "\n",
    "            train_accuracies, train_losses = [], []\n",
    "            val_accuracies, val_losses = [], []\n",
    "\n",
    "            lowest_loss = 100000000.0\n",
    "            best_accuracy = -1000000.0\n",
    "            no_improvement_count = 0\n",
    "\n",
    "            model = model.to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            init_time = time.time()\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                model_file_name = \"mn_{}_loss_{}_lr_{}.pth\".format(model_name, loss_fn_name, lr)\n",
    "\n",
    "                train_acc, train_loss = train(model, optimizer, loss_fn)\n",
    "                train_accuracies.append(train_acc)\n",
    "                train_losses.append(train_loss)\n",
    "\n",
    "                val_acc, val_loss = evalution(model, val_loader, loss_fn)\n",
    "                val_accuracies.append(val_acc)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                print(\"Epoch: {}/{} | Train Loss: {:.5f} | Train Acc: {:.3f} | Val Acc: {:.3f}\".format(epoch, epochs, train_loss, train_acc, val_acc))\n",
    "\n",
    "                if round(best_accuracy, 3) < round(val_acc, 3):\n",
    "                    best_accuracy = val_acc\n",
    "                    no_improvement_count = 0\n",
    "                    test_acc, test_loss, all_preductions, all_labels = evalution(model, test_loader, loss_fn, type=\"test\")\n",
    "                    cnf_matrix = confusion_matrix(all_labels, all_preductions)\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'train_acc': train_acc,\n",
    "                        'val_acc': val_acc,\n",
    "                        'test_acc': test_acc,\n",
    "                        'confusion_matrix': cnf_matrix,\n",
    "                        'time': str(time.time() - init_time),\n",
    "                        'model_state_dict': optimizer.state_dict(),\n",
    "                    }, model_file_name)\n",
    "\n",
    "                    print(\"Saving Best Model. Test Accuracy: {}\".format(test_acc))\n",
    "\n",
    "                    # Saving Metrics\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"train_acc\"), \"wb\") as file:\n",
    "                        pickle.dump(train_accuracies, file)\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"val_acc\"), \"wb\") as file:\n",
    "                        pickle.dump(val_accuracies, file)\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"train_loss\"), \"wb\") as file:\n",
    "                        pickle.dump(train_losses, file)\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"val_loss\"), \"wb\") as file:\n",
    "                        pickle.dump(val_losses, file)\n",
    "                    \n",
    "                else:\n",
    "                    no_improvement_count += 1\n",
    "                    print(\"No Improvement: {}\".format(no_improvement_count))\n",
    "\n",
    "                if no_improvement_count == patience:\n",
    "                    break\n",
    "\n",
    "\n",
    "# test_acc, test_loss, all_preductions, all_labels = evalution(test_loader, \"test\")\n",
    "# print(confusion_matrix(all_labels, all_preductions))\n",
    "# print(\"Test Acc: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1: mn_small_loss_nll_lr_0.0001\n",
      "0.1: mn_small_loss_nll_lr_0.01\n",
      "0.1: mn_small_loss_nll_lr_0.1\n",
      "0.1: mn_small_loss_ce_lr_0.0001\n",
      "0.1001: mn_small_loss_ce_lr_0.01\n",
      "0.1: mn_small_loss_ce_lr_0.1\n",
      "0.841: mn_medium_loss_nll_lr_0.0001\n",
      "0.2414: mn_medium_loss_nll_lr_0.01\n",
      "0.165: mn_medium_loss_nll_lr_0.1\n",
      "0.5212: mn_medium_loss_ce_lr_0.0001\n",
      "0.5708: mn_medium_loss_ce_lr_0.01\n",
      "0.5751: mn_medium_loss_ce_lr_0.1\n",
      "0.884: mn_large_loss_nll_lr_0.0001\n",
      "0.1868: mn_large_loss_nll_lr_0.01\n",
      "0.1: mn_large_loss_nll_lr_0.1\n",
      "0.1: mn_large_loss_ce_lr_0.0001\n",
      "0.552: mn_large_loss_ce_lr_0.01\n",
      "0.5539: mn_large_loss_ce_lr_0.1\n"
     ]
    }
   ],
   "source": [
    "models = [SmallMLP(), MediumMLP(), LargeMLP()]\n",
    "model_names = [\"small\", \"medium\", \"large\"]\n",
    "learning_rates = [0.0001, 0.01, 0.1]\n",
    "loss_functions = [nn.NLLLoss(), nn.CrossEntropyLoss()]\n",
    "loss_fn_names = ['nll', 'ce']\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for loss_fn, loss_fn_name in zip(loss_functions, loss_fn_names):\n",
    "        for lr in learning_rates:\n",
    "\n",
    "\n",
    "            model_file_name = \"mn_{}_loss_{}_lr_{}\".format(model_name, loss_fn_name, lr)\n",
    "            model = torch.load(model_file_name)\n",
    "            print(\"{}: {}\".format(model['test_acc'], model_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"mn_small_loss_ce_lr_001_2.pth\")\n",
    "model['test_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 | Train Loss: 0.00883 | Train Acc: 0.822 | Val Acc: 0.904\n",
      "Saving Best Model. Test Accuracy: 0.79\n",
      "Epoch: 1/1000 | Train Loss: 0.00474 | Train Acc: 0.906 | Val Acc: 0.926\n",
      "Saving Best Model. Test Accuracy: 0.8377\n",
      "Epoch: 2/1000 | Train Loss: 0.00382 | Train Acc: 0.925 | Val Acc: 0.938\n",
      "Saving Best Model. Test Accuracy: 0.855\n",
      "Epoch: 3/1000 | Train Loss: 0.00314 | Train Acc: 0.938 | Val Acc: 0.945\n",
      "Saving Best Model. Test Accuracy: 0.8742\n",
      "Epoch: 4/1000 | Train Loss: 0.00276 | Train Acc: 0.945 | Val Acc: 0.945\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 0.00248 | Train Acc: 0.950 | Val Acc: 0.951\n",
      "Saving Best Model. Test Accuracy: 0.8859\n",
      "Epoch: 6/1000 | Train Loss: 0.00228 | Train Acc: 0.953 | Val Acc: 0.954\n",
      "Saving Best Model. Test Accuracy: 0.8909\n",
      "Epoch: 7/1000 | Train Loss: 0.00207 | Train Acc: 0.957 | Val Acc: 0.953\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00202 | Train Acc: 0.959 | Val Acc: 0.953\n",
      "No Improvement: 2\n",
      "Epoch: 9/1000 | Train Loss: 0.00187 | Train Acc: 0.960 | Val Acc: 0.952\n",
      "No Improvement: 3\n",
      "Epoch: 10/1000 | Train Loss: 0.00173 | Train Acc: 0.964 | Val Acc: 0.955\n",
      "Saving Best Model. Test Accuracy: 0.8986\n",
      "Epoch: 11/1000 | Train Loss: 0.00167 | Train Acc: 0.966 | Val Acc: 0.953\n",
      "No Improvement: 1\n",
      "Epoch: 12/1000 | Train Loss: 0.00156 | Train Acc: 0.968 | Val Acc: 0.957\n",
      "Saving Best Model. Test Accuracy: 0.8835\n",
      "Epoch: 13/1000 | Train Loss: 0.00145 | Train Acc: 0.969 | Val Acc: 0.959\n",
      "Saving Best Model. Test Accuracy: 0.8966\n",
      "Epoch: 14/1000 | Train Loss: 0.00149 | Train Acc: 0.969 | Val Acc: 0.960\n",
      "Saving Best Model. Test Accuracy: 0.8981\n",
      "Epoch: 15/1000 | Train Loss: 0.00134 | Train Acc: 0.973 | Val Acc: 0.958\n",
      "No Improvement: 1\n",
      "Epoch: 16/1000 | Train Loss: 0.00134 | Train Acc: 0.972 | Val Acc: 0.960\n",
      "No Improvement: 2\n",
      "Epoch: 17/1000 | Train Loss: 0.00132 | Train Acc: 0.972 | Val Acc: 0.960\n",
      "No Improvement: 3\n",
      "Epoch: 18/1000 | Train Loss: 0.00128 | Train Acc: 0.973 | Val Acc: 0.959\n",
      "No Improvement: 4\n",
      "Epoch: 19/1000 | Train Loss: 0.00121 | Train Acc: 0.975 | Val Acc: 0.962\n",
      "Saving Best Model. Test Accuracy: 0.9032\n",
      "Epoch: 20/1000 | Train Loss: 0.00123 | Train Acc: 0.974 | Val Acc: 0.957\n",
      "No Improvement: 1\n",
      "Epoch: 21/1000 | Train Loss: 0.00122 | Train Acc: 0.973 | Val Acc: 0.960\n",
      "No Improvement: 2\n",
      "Epoch: 22/1000 | Train Loss: 0.00111 | Train Acc: 0.977 | Val Acc: 0.959\n",
      "No Improvement: 3\n",
      "Epoch: 23/1000 | Train Loss: 0.00111 | Train Acc: 0.978 | Val Acc: 0.956\n",
      "No Improvement: 4\n",
      "Epoch: 24/1000 | Train Loss: 0.00107 | Train Acc: 0.977 | Val Acc: 0.963\n",
      "Saving Best Model. Test Accuracy: 0.907\n",
      "Epoch: 25/1000 | Train Loss: 0.00106 | Train Acc: 0.978 | Val Acc: 0.961\n",
      "No Improvement: 1\n",
      "Epoch: 26/1000 | Train Loss: 0.00106 | Train Acc: 0.977 | Val Acc: 0.962\n",
      "No Improvement: 2\n",
      "Epoch: 27/1000 | Train Loss: 0.00100 | Train Acc: 0.979 | Val Acc: 0.962\n",
      "No Improvement: 3\n",
      "Epoch: 28/1000 | Train Loss: 0.00105 | Train Acc: 0.978 | Val Acc: 0.962\n",
      "No Improvement: 4\n",
      "Epoch: 29/1000 | Train Loss: 0.00089 | Train Acc: 0.982 | Val Acc: 0.961\n",
      "No Improvement: 5\n",
      "Epoch: 30/1000 | Train Loss: 0.00101 | Train Acc: 0.980 | Val Acc: 0.959\n",
      "No Improvement: 6\n",
      "Epoch: 31/1000 | Train Loss: 0.00100 | Train Acc: 0.981 | Val Acc: 0.962\n",
      "No Improvement: 7\n",
      "Epoch: 32/1000 | Train Loss: 0.00092 | Train Acc: 0.981 | Val Acc: 0.960\n",
      "No Improvement: 8\n",
      "Epoch: 33/1000 | Train Loss: 0.00103 | Train Acc: 0.979 | Val Acc: 0.962\n",
      "No Improvement: 9\n",
      "Epoch: 34/1000 | Train Loss: 0.00092 | Train Acc: 0.981 | Val Acc: 0.963\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.01066 | Train Acc: 0.817 | Val Acc: 0.867\n",
      "Saving Best Model. Test Accuracy: 0.7366\n",
      "Epoch: 1/1000 | Train Loss: 0.01043 | Train Acc: 0.820 | Val Acc: 0.852\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: 0.01018 | Train Acc: 0.824 | Val Acc: 0.859\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: 0.00994 | Train Acc: 0.827 | Val Acc: 0.872\n",
      "Saving Best Model. Test Accuracy: 0.7491\n",
      "Epoch: 4/1000 | Train Loss: 0.01011 | Train Acc: 0.827 | Val Acc: 0.863\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 0.00994 | Train Acc: 0.830 | Val Acc: 0.880\n",
      "Saving Best Model. Test Accuracy: 0.7546\n",
      "Epoch: 6/1000 | Train Loss: 0.00995 | Train Acc: 0.834 | Val Acc: 0.870\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: 0.00969 | Train Acc: 0.840 | Val Acc: 0.865\n",
      "No Improvement: 2\n",
      "Epoch: 8/1000 | Train Loss: 0.00936 | Train Acc: 0.841 | Val Acc: 0.886\n",
      "Saving Best Model. Test Accuracy: 0.7679\n",
      "Epoch: 9/1000 | Train Loss: 0.00973 | Train Acc: 0.835 | Val Acc: 0.890\n",
      "Saving Best Model. Test Accuracy: 0.7648\n",
      "Epoch: 10/1000 | Train Loss: 0.00952 | Train Acc: 0.840 | Val Acc: 0.863\n",
      "No Improvement: 1\n",
      "Epoch: 11/1000 | Train Loss: 0.01000 | Train Acc: 0.827 | Val Acc: 0.858\n",
      "No Improvement: 2\n",
      "Epoch: 12/1000 | Train Loss: 0.00924 | Train Acc: 0.841 | Val Acc: 0.880\n",
      "No Improvement: 3\n",
      "Epoch: 13/1000 | Train Loss: 0.01024 | Train Acc: 0.830 | Val Acc: 0.873\n",
      "No Improvement: 4\n",
      "Epoch: 14/1000 | Train Loss: 0.01021 | Train Acc: 0.829 | Val Acc: 0.857\n",
      "No Improvement: 5\n",
      "Epoch: 15/1000 | Train Loss: 0.00926 | Train Acc: 0.838 | Val Acc: 0.863\n",
      "No Improvement: 6\n",
      "Epoch: 16/1000 | Train Loss: 0.01014 | Train Acc: 0.827 | Val Acc: 0.876\n",
      "No Improvement: 7\n",
      "Epoch: 17/1000 | Train Loss: 0.00973 | Train Acc: 0.834 | Val Acc: 0.875\n",
      "No Improvement: 8\n",
      "Epoch: 18/1000 | Train Loss: 0.00933 | Train Acc: 0.840 | Val Acc: 0.873\n",
      "No Improvement: 9\n",
      "Epoch: 19/1000 | Train Loss: 0.00958 | Train Acc: 0.836 | Val Acc: 0.867\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.03742 | Train Acc: 0.110 | Val Acc: 0.097\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: 0.03615 | Train Acc: 0.101 | Val Acc: 0.099\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 2/1000 | Train Loss: 0.03643 | Train Acc: 0.099 | Val Acc: 0.100\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 3/1000 | Train Loss: 0.03612 | Train Acc: 0.102 | Val Acc: 0.101\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 4/1000 | Train Loss: 0.03611 | Train Acc: 0.100 | Val Acc: 0.101\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 0.03613 | Train Acc: 0.098 | Val Acc: 0.101\n",
      "No Improvement: 2\n",
      "Epoch: 6/1000 | Train Loss: 0.03612 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 3\n",
      "Epoch: 7/1000 | Train Loss: 0.03613 | Train Acc: 0.100 | Val Acc: 0.101\n",
      "No Improvement: 4\n",
      "Epoch: 8/1000 | Train Loss: 0.03613 | Train Acc: 0.100 | Val Acc: 0.101\n",
      "No Improvement: 5\n",
      "Epoch: 9/1000 | Train Loss: 0.03612 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 6\n",
      "Epoch: 10/1000 | Train Loss: 0.03619 | Train Acc: 0.098 | Val Acc: 0.099\n",
      "No Improvement: 7\n",
      "Epoch: 11/1000 | Train Loss: 0.03611 | Train Acc: 0.098 | Val Acc: 0.100\n",
      "No Improvement: 8\n",
      "Epoch: 12/1000 | Train Loss: 0.03733 | Train Acc: 0.100 | Val Acc: 0.100\n",
      "No Improvement: 9\n",
      "Epoch: 13/1000 | Train Loss: 0.03618 | Train Acc: 0.099 | Val Acc: 0.099\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.00617 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -0.01650 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -0.02813 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -0.03909 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -0.05006 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -0.06104 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -0.07202 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -0.08300 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -0.09398 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -0.10495 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -0.11593 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.17571 | Train Acc: 0.100 | Val Acc: 0.095\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -0.28590 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -0.39554 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -0.50525 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -0.61502 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -0.72478 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -0.83453 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -0.94428 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -1.05408 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -1.16384 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -1.27362 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -1.87740 | Train Acc: 0.100 | Val Acc: 0.104\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -2.97489 | Train Acc: 0.098 | Val Acc: 0.104\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -4.07220 | Train Acc: 0.099 | Val Acc: 0.095\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -5.16914 | Train Acc: 0.100 | Val Acc: 0.095\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -6.26639 | Train Acc: 0.101 | Val Acc: 0.095\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -46706339.10168 | Train Acc: 0.100 | Val Acc: 0.099\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -29973152795.81867 | Train Acc: 0.100 | Val Acc: 0.101\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -226999703426.38934 | Train Acc: 0.099 | Val Acc: 0.102\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -819735425362.60266 | Train Acc: 0.099 | Val Acc: 0.102\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -1994720471416.83203 | Train Acc: 0.100 | Val Acc: 0.102\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -3916221212087.63721 | Train Acc: 0.100 | Val Acc: 0.102\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00695 | Train Acc: 0.868 | Val Acc: 0.933\n",
      "Saving Best Model. Test Accuracy: 0.8525\n",
      "Epoch: 1/1000 | Train Loss: 0.00372 | Train Acc: 0.926 | Val Acc: 0.947\n",
      "Saving Best Model. Test Accuracy: 0.882\n",
      "Epoch: 2/1000 | Train Loss: 0.00291 | Train Acc: 0.942 | Val Acc: 0.956\n",
      "Saving Best Model. Test Accuracy: 0.8919\n",
      "Epoch: 3/1000 | Train Loss: 0.00238 | Train Acc: 0.953 | Val Acc: 0.959\n",
      "Saving Best Model. Test Accuracy: 0.903\n",
      "Epoch: 4/1000 | Train Loss: 0.00207 | Train Acc: 0.958 | Val Acc: 0.961\n",
      "Saving Best Model. Test Accuracy: 0.8993\n",
      "Epoch: 5/1000 | Train Loss: 0.00176 | Train Acc: 0.964 | Val Acc: 0.961\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: 0.00154 | Train Acc: 0.968 | Val Acc: 0.963\n",
      "Saving Best Model. Test Accuracy: 0.9083\n",
      "Epoch: 7/1000 | Train Loss: 0.00144 | Train Acc: 0.971 | Val Acc: 0.960\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00124 | Train Acc: 0.974 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.9112\n",
      "Epoch: 9/1000 | Train Loss: 0.00117 | Train Acc: 0.976 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: 0.00103 | Train Acc: 0.979 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 11/1000 | Train Loss: 0.00097 | Train Acc: 0.979 | Val Acc: 0.965\n",
      "No Improvement: 3\n",
      "Epoch: 12/1000 | Train Loss: 0.00095 | Train Acc: 0.980 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.916\n",
      "Epoch: 13/1000 | Train Loss: 0.00089 | Train Acc: 0.981 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 14/1000 | Train Loss: 0.00080 | Train Acc: 0.983 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 15/1000 | Train Loss: 0.00073 | Train Acc: 0.985 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9198\n",
      "Epoch: 16/1000 | Train Loss: 0.00069 | Train Acc: 0.985 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 17/1000 | Train Loss: 0.00069 | Train Acc: 0.985 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 18/1000 | Train Loss: 0.00062 | Train Acc: 0.987 | Val Acc: 0.968\n",
      "No Improvement: 3\n",
      "Epoch: 19/1000 | Train Loss: 0.00067 | Train Acc: 0.986 | Val Acc: 0.969\n",
      "No Improvement: 4\n",
      "Epoch: 20/1000 | Train Loss: 0.00061 | Train Acc: 0.987 | Val Acc: 0.970\n",
      "No Improvement: 5\n",
      "Epoch: 21/1000 | Train Loss: 0.00058 | Train Acc: 0.988 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 22/1000 | Train Loss: 0.00054 | Train Acc: 0.989 | Val Acc: 0.969\n",
      "No Improvement: 7\n",
      "Epoch: 23/1000 | Train Loss: 0.00055 | Train Acc: 0.988 | Val Acc: 0.971\n",
      "No Improvement: 8\n",
      "Epoch: 24/1000 | Train Loss: 0.00050 | Train Acc: 0.989 | Val Acc: 0.970\n",
      "No Improvement: 9\n",
      "Epoch: 25/1000 | Train Loss: 0.00053 | Train Acc: 0.989 | Val Acc: 0.971\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00388 | Train Acc: 0.925 | Val Acc: 0.942\n",
      "Saving Best Model. Test Accuracy: 0.8539\n",
      "Epoch: 1/1000 | Train Loss: 0.00279 | Train Acc: 0.945 | Val Acc: 0.955\n",
      "Saving Best Model. Test Accuracy: 0.8926\n",
      "Epoch: 2/1000 | Train Loss: 0.00225 | Train Acc: 0.955 | Val Acc: 0.960\n",
      "Saving Best Model. Test Accuracy: 0.8972\n",
      "Epoch: 3/1000 | Train Loss: 0.00199 | Train Acc: 0.959 | Val Acc: 0.962\n",
      "Saving Best Model. Test Accuracy: 0.9076\n",
      "Epoch: 4/1000 | Train Loss: 0.00179 | Train Acc: 0.964 | Val Acc: 0.963\n",
      "Saving Best Model. Test Accuracy: 0.9114\n",
      "Epoch: 5/1000 | Train Loss: 0.00164 | Train Acc: 0.966 | Val Acc: 0.962\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: 0.00153 | Train Acc: 0.969 | Val Acc: 0.964\n",
      "Saving Best Model. Test Accuracy: 0.9125\n",
      "Epoch: 7/1000 | Train Loss: 0.00141 | Train Acc: 0.971 | Val Acc: 0.963\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00130 | Train Acc: 0.973 | Val Acc: 0.962\n",
      "No Improvement: 2\n",
      "Epoch: 9/1000 | Train Loss: 0.00126 | Train Acc: 0.974 | Val Acc: 0.963\n",
      "No Improvement: 3\n",
      "Epoch: 10/1000 | Train Loss: 0.00123 | Train Acc: 0.976 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.9095\n",
      "Epoch: 11/1000 | Train Loss: 0.00109 | Train Acc: 0.978 | Val Acc: 0.966\n",
      "Saving Best Model. Test Accuracy: 0.9112\n",
      "Epoch: 12/1000 | Train Loss: 0.00111 | Train Acc: 0.978 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9149\n",
      "Epoch: 13/1000 | Train Loss: 0.00100 | Train Acc: 0.979 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 14/1000 | Train Loss: 0.00098 | Train Acc: 0.980 | Val Acc: 0.966\n",
      "No Improvement: 2\n",
      "Epoch: 15/1000 | Train Loss: 0.00094 | Train Acc: 0.981 | Val Acc: 0.966\n",
      "No Improvement: 3\n",
      "Epoch: 16/1000 | Train Loss: 0.00089 | Train Acc: 0.981 | Val Acc: 0.967\n",
      "No Improvement: 4\n",
      "Epoch: 17/1000 | Train Loss: 0.00087 | Train Acc: 0.982 | Val Acc: 0.967\n",
      "No Improvement: 5\n",
      "Epoch: 18/1000 | Train Loss: 0.00083 | Train Acc: 0.982 | Val Acc: 0.967\n",
      "No Improvement: 6\n",
      "Epoch: 19/1000 | Train Loss: 0.00079 | Train Acc: 0.984 | Val Acc: 0.968\n",
      "No Improvement: 7\n",
      "Epoch: 20/1000 | Train Loss: 0.00082 | Train Acc: 0.983 | Val Acc: 0.970\n",
      "No Improvement: 8\n",
      "Epoch: 21/1000 | Train Loss: 0.00070 | Train Acc: 0.986 | Val Acc: 0.969\n",
      "No Improvement: 9\n",
      "Epoch: 22/1000 | Train Loss: 0.00077 | Train Acc: 0.984 | Val Acc: 0.968\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00687 | Train Acc: 0.875 | Val Acc: 0.925\n",
      "Saving Best Model. Test Accuracy: 0.8369\n",
      "Epoch: 1/1000 | Train Loss: 0.00523 | Train Acc: 0.906 | Val Acc: 0.940\n",
      "Saving Best Model. Test Accuracy: 0.8565\n",
      "Epoch: 2/1000 | Train Loss: 0.00466 | Train Acc: 0.915 | Val Acc: 0.947\n",
      "Saving Best Model. Test Accuracy: 0.8711\n",
      "Epoch: 3/1000 | Train Loss: 0.00439 | Train Acc: 0.921 | Val Acc: 0.945\n",
      "No Improvement: 1\n",
      "Epoch: 4/1000 | Train Loss: 0.00380 | Train Acc: 0.931 | Val Acc: 0.954\n",
      "Saving Best Model. Test Accuracy: 0.8781\n",
      "Epoch: 5/1000 | Train Loss: 0.00376 | Train Acc: 0.934 | Val Acc: 0.955\n",
      "Saving Best Model. Test Accuracy: 0.8847\n",
      "Epoch: 6/1000 | Train Loss: 0.00346 | Train Acc: 0.939 | Val Acc: 0.952\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: 0.00351 | Train Acc: 0.938 | Val Acc: 0.954\n",
      "No Improvement: 2\n",
      "Epoch: 8/1000 | Train Loss: 0.00323 | Train Acc: 0.943 | Val Acc: 0.960\n",
      "Saving Best Model. Test Accuracy: 0.9005\n",
      "Epoch: 9/1000 | Train Loss: 0.00303 | Train Acc: 0.946 | Val Acc: 0.956\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: 0.00313 | Train Acc: 0.946 | Val Acc: 0.961\n",
      "Saving Best Model. Test Accuracy: 0.9038\n",
      "Epoch: 11/1000 | Train Loss: 0.00277 | Train Acc: 0.951 | Val Acc: 0.963\n",
      "Saving Best Model. Test Accuracy: 0.896\n",
      "Epoch: 12/1000 | Train Loss: 0.00272 | Train Acc: 0.952 | Val Acc: 0.956\n",
      "No Improvement: 1\n",
      "Epoch: 13/1000 | Train Loss: 0.00279 | Train Acc: 0.952 | Val Acc: 0.962\n",
      "No Improvement: 2\n",
      "Epoch: 14/1000 | Train Loss: 0.00258 | Train Acc: 0.955 | Val Acc: 0.962\n",
      "No Improvement: 3\n",
      "Epoch: 15/1000 | Train Loss: 0.00245 | Train Acc: 0.959 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.9052\n",
      "Epoch: 16/1000 | Train Loss: 0.00243 | Train Acc: 0.958 | Val Acc: 0.963\n",
      "No Improvement: 1\n",
      "Epoch: 17/1000 | Train Loss: 0.00247 | Train Acc: 0.958 | Val Acc: 0.962\n",
      "No Improvement: 2\n",
      "Epoch: 18/1000 | Train Loss: 0.00229 | Train Acc: 0.962 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.9081\n",
      "Epoch: 19/1000 | Train Loss: 0.00231 | Train Acc: 0.961 | Val Acc: 0.961\n",
      "No Improvement: 1\n",
      "Epoch: 20/1000 | Train Loss: 0.00233 | Train Acc: 0.962 | Val Acc: 0.959\n",
      "No Improvement: 2\n",
      "Epoch: 21/1000 | Train Loss: 0.00241 | Train Acc: 0.960 | Val Acc: 0.964\n",
      "No Improvement: 3\n",
      "Epoch: 22/1000 | Train Loss: 0.00215 | Train Acc: 0.962 | Val Acc: 0.965\n",
      "No Improvement: 4\n",
      "Epoch: 23/1000 | Train Loss: 0.00218 | Train Acc: 0.962 | Val Acc: 0.962\n",
      "No Improvement: 5\n",
      "Epoch: 24/1000 | Train Loss: 0.00206 | Train Acc: 0.965 | Val Acc: 0.966\n",
      "No Improvement: 6\n",
      "Epoch: 25/1000 | Train Loss: 0.00210 | Train Acc: 0.964 | Val Acc: 0.968\n",
      "Saving Best Model. Test Accuracy: 0.9155\n",
      "Epoch: 26/1000 | Train Loss: 0.00212 | Train Acc: 0.965 | Val Acc: 0.964\n",
      "No Improvement: 1\n",
      "Epoch: 27/1000 | Train Loss: 0.00195 | Train Acc: 0.968 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 28/1000 | Train Loss: 0.00218 | Train Acc: 0.963 | Val Acc: 0.965\n",
      "No Improvement: 3\n",
      "Epoch: 29/1000 | Train Loss: 0.00212 | Train Acc: 0.965 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9207\n",
      "Epoch: 30/1000 | Train Loss: 0.00197 | Train Acc: 0.967 | Val Acc: 0.963\n",
      "No Improvement: 1\n",
      "Epoch: 31/1000 | Train Loss: 0.00193 | Train Acc: 0.969 | Val Acc: 0.969\n",
      "No Improvement: 2\n",
      "Epoch: 32/1000 | Train Loss: 0.00187 | Train Acc: 0.969 | Val Acc: 0.964\n",
      "No Improvement: 3\n",
      "Epoch: 33/1000 | Train Loss: 0.00195 | Train Acc: 0.968 | Val Acc: 0.967\n",
      "No Improvement: 4\n",
      "Epoch: 34/1000 | Train Loss: 0.00189 | Train Acc: 0.967 | Val Acc: 0.968\n",
      "No Improvement: 5\n",
      "Epoch: 35/1000 | Train Loss: 0.00171 | Train Acc: 0.972 | Val Acc: 0.968\n",
      "No Improvement: 6\n",
      "Epoch: 36/1000 | Train Loss: 0.00190 | Train Acc: 0.970 | Val Acc: 0.966\n",
      "No Improvement: 7\n",
      "Epoch: 37/1000 | Train Loss: 0.00201 | Train Acc: 0.968 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9155\n",
      "Epoch: 38/1000 | Train Loss: 0.00179 | Train Acc: 0.970 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 39/1000 | Train Loss: 0.00170 | Train Acc: 0.973 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 40/1000 | Train Loss: 0.00175 | Train Acc: 0.971 | Val Acc: 0.968\n",
      "No Improvement: 3\n",
      "Epoch: 41/1000 | Train Loss: 0.00174 | Train Acc: 0.972 | Val Acc: 0.964\n",
      "No Improvement: 4\n",
      "Epoch: 42/1000 | Train Loss: 0.00173 | Train Acc: 0.971 | Val Acc: 0.967\n",
      "No Improvement: 5\n",
      "Epoch: 43/1000 | Train Loss: 0.00170 | Train Acc: 0.972 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 44/1000 | Train Loss: 0.00168 | Train Acc: 0.973 | Val Acc: 0.970\n",
      "No Improvement: 7\n",
      "Epoch: 45/1000 | Train Loss: 0.00166 | Train Acc: 0.973 | Val Acc: 0.963\n",
      "No Improvement: 8\n",
      "Epoch: 46/1000 | Train Loss: 0.00170 | Train Acc: 0.973 | Val Acc: 0.965\n",
      "No Improvement: 9\n",
      "Epoch: 47/1000 | Train Loss: 0.00169 | Train Acc: 0.974 | Val Acc: 0.969\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.55200 | Train Acc: 0.970 | Val Acc: 0.964\n",
      "Saving Best Model. Test Accuracy: 0.9169\n",
      "Epoch: 1/1000 | Train Loss: -1.31680 | Train Acc: 0.946 | Val Acc: 0.956\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -2.48587 | Train Acc: 0.924 | Val Acc: 0.948\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -4.08400 | Train Acc: 0.912 | Val Acc: 0.939\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -6.04818 | Train Acc: 0.896 | Val Acc: 0.935\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -8.42437 | Train Acc: 0.887 | Val Acc: 0.925\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -11.16854 | Train Acc: 0.879 | Val Acc: 0.925\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -14.27361 | Train Acc: 0.870 | Val Acc: 0.915\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -17.73333 | Train Acc: 0.863 | Val Acc: 0.916\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -21.47120 | Train Acc: 0.856 | Val Acc: 0.907\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -25.58782 | Train Acc: 0.848 | Val Acc: 0.899\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -55.92742 | Train Acc: 0.811 | Val Acc: 0.838\n",
      "Saving Best Model. Test Accuracy: 0.7629\n",
      "Epoch: 1/1000 | Train Loss: -153.26587 | Train Acc: 0.735 | Val Acc: 0.746\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -323.62021 | Train Acc: 0.651 | Val Acc: 0.687\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -563.63278 | Train Acc: 0.577 | Val Acc: 0.640\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -865.07018 | Train Acc: 0.481 | Val Acc: 0.487\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -1219.94524 | Train Acc: 0.375 | Val Acc: 0.264\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -1623.27812 | Train Acc: 0.238 | Val Acc: 0.265\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -2072.99528 | Train Acc: 0.223 | Val Acc: 0.265\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -2569.44594 | Train Acc: 0.222 | Val Acc: 0.177\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -3108.19497 | Train Acc: 0.205 | Val Acc: 0.176\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -3706.31048 | Train Acc: 0.214 | Val Acc: 0.181\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -7987.23432 | Train Acc: 0.273 | Val Acc: 0.179\n",
      "Saving Best Model. Test Accuracy: 0.1684\n",
      "Epoch: 1/1000 | Train Loss: -20999.57300 | Train Acc: 0.221 | Val Acc: 0.300\n",
      "Saving Best Model. Test Accuracy: 0.2591\n",
      "Epoch: 2/1000 | Train Loss: -41858.04479 | Train Acc: 0.288 | Val Acc: 0.275\n",
      "No Improvement: 1\n",
      "Epoch: 3/1000 | Train Loss: -70232.28016 | Train Acc: 0.328 | Val Acc: 0.279\n",
      "No Improvement: 2\n",
      "Epoch: 4/1000 | Train Loss: -104823.88156 | Train Acc: 0.309 | Val Acc: 0.368\n",
      "Saving Best Model. Test Accuracy: 0.3324\n",
      "Epoch: 5/1000 | Train Loss: -145174.12470 | Train Acc: 0.350 | Val Acc: 0.279\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: -191258.33060 | Train Acc: 0.384 | Val Acc: 0.357\n",
      "No Improvement: 2\n",
      "Epoch: 7/1000 | Train Loss: -243170.46779 | Train Acc: 0.357 | Val Acc: 0.362\n",
      "No Improvement: 3\n",
      "Epoch: 8/1000 | Train Loss: -300121.96940 | Train Acc: 0.398 | Val Acc: 0.450\n",
      "Saving Best Model. Test Accuracy: 0.3962\n",
      "Epoch: 9/1000 | Train Loss: -362462.72187 | Train Acc: 0.365 | Val Acc: 0.359\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: -429525.20950 | Train Acc: 0.326 | Val Acc: 0.357\n",
      "No Improvement: 2\n",
      "Epoch: 11/1000 | Train Loss: -502771.28804 | Train Acc: 0.347 | Val Acc: 0.352\n",
      "No Improvement: 3\n",
      "Epoch: 12/1000 | Train Loss: -579982.01833 | Train Acc: 0.316 | Val Acc: 0.347\n",
      "No Improvement: 4\n",
      "Epoch: 13/1000 | Train Loss: -661381.40667 | Train Acc: 0.327 | Val Acc: 0.447\n",
      "No Improvement: 5\n",
      "Epoch: 14/1000 | Train Loss: -749041.35458 | Train Acc: 0.383 | Val Acc: 0.448\n",
      "No Improvement: 6\n",
      "Epoch: 15/1000 | Train Loss: -841550.60700 | Train Acc: 0.431 | Val Acc: 0.442\n",
      "No Improvement: 7\n",
      "Epoch: 16/1000 | Train Loss: -938481.04225 | Train Acc: 0.404 | Val Acc: 0.455\n",
      "Saving Best Model. Test Accuracy: 0.3891\n",
      "Epoch: 17/1000 | Train Loss: -1040348.49625 | Train Acc: 0.439 | Val Acc: 0.446\n",
      "No Improvement: 1\n",
      "Epoch: 18/1000 | Train Loss: -1146415.77733 | Train Acc: 0.378 | Val Acc: 0.444\n",
      "No Improvement: 2\n",
      "Epoch: 19/1000 | Train Loss: -1258159.38467 | Train Acc: 0.438 | Val Acc: 0.446\n",
      "No Improvement: 3\n",
      "Epoch: 20/1000 | Train Loss: -1374742.72017 | Train Acc: 0.396 | Val Acc: 0.443\n",
      "No Improvement: 4\n",
      "Epoch: 21/1000 | Train Loss: -1495351.54950 | Train Acc: 0.393 | Val Acc: 0.359\n",
      "No Improvement: 5\n",
      "Epoch: 22/1000 | Train Loss: -1622921.32317 | Train Acc: 0.380 | Val Acc: 0.357\n",
      "No Improvement: 6\n",
      "Epoch: 23/1000 | Train Loss: -1752074.71317 | Train Acc: 0.442 | Val Acc: 0.377\n",
      "No Improvement: 7\n",
      "Epoch: 24/1000 | Train Loss: -1888866.60967 | Train Acc: 0.388 | Val Acc: 0.450\n",
      "No Improvement: 8\n",
      "Epoch: 25/1000 | Train Loss: -2029970.47800 | Train Acc: 0.408 | Val Acc: 0.447\n",
      "No Improvement: 9\n",
      "Epoch: 26/1000 | Train Loss: -2173575.98500 | Train Acc: 0.414 | Val Acc: 0.355\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00792 | Train Acc: 0.849 | Val Acc: 0.929\n",
      "Saving Best Model. Test Accuracy: 0.8367\n",
      "Epoch: 1/1000 | Train Loss: 0.00433 | Train Acc: 0.916 | Val Acc: 0.948\n",
      "Saving Best Model. Test Accuracy: 0.8769\n",
      "Epoch: 2/1000 | Train Loss: 0.00342 | Train Acc: 0.934 | Val Acc: 0.949\n",
      "Saving Best Model. Test Accuracy: 0.8795\n",
      "Epoch: 3/1000 | Train Loss: 0.00289 | Train Acc: 0.945 | Val Acc: 0.958\n",
      "Saving Best Model. Test Accuracy: 0.9042\n",
      "Epoch: 4/1000 | Train Loss: 0.00244 | Train Acc: 0.951 | Val Acc: 0.961\n",
      "Saving Best Model. Test Accuracy: 0.9146\n",
      "Epoch: 5/1000 | Train Loss: 0.00222 | Train Acc: 0.956 | Val Acc: 0.961\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: 0.00191 | Train Acc: 0.964 | Val Acc: 0.964\n",
      "Saving Best Model. Test Accuracy: 0.9085\n",
      "Epoch: 7/1000 | Train Loss: 0.00174 | Train Acc: 0.966 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.9058\n",
      "Epoch: 8/1000 | Train Loss: 0.00159 | Train Acc: 0.968 | Val Acc: 0.965\n",
      "No Improvement: 1\n",
      "Epoch: 9/1000 | Train Loss: 0.00147 | Train Acc: 0.970 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.9149\n",
      "Epoch: 10/1000 | Train Loss: 0.00131 | Train Acc: 0.973 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 11/1000 | Train Loss: 0.00121 | Train Acc: 0.976 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9178\n",
      "Epoch: 12/1000 | Train Loss: 0.00120 | Train Acc: 0.976 | Val Acc: 0.968\n",
      "No Improvement: 1\n",
      "Epoch: 13/1000 | Train Loss: 0.00103 | Train Acc: 0.979 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 14/1000 | Train Loss: 0.00104 | Train Acc: 0.979 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 15/1000 | Train Loss: 0.00091 | Train Acc: 0.981 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9178\n",
      "Epoch: 16/1000 | Train Loss: 0.00084 | Train Acc: 0.982 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 17/1000 | Train Loss: 0.00086 | Train Acc: 0.982 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 18/1000 | Train Loss: 0.00077 | Train Acc: 0.984 | Val Acc: 0.970\n",
      "No Improvement: 3\n",
      "Epoch: 19/1000 | Train Loss: 0.00077 | Train Acc: 0.984 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9208\n",
      "Epoch: 20/1000 | Train Loss: 0.00068 | Train Acc: 0.986 | Val Acc: 0.974\n",
      "Saving Best Model. Test Accuracy: 0.9191\n",
      "Epoch: 21/1000 | Train Loss: 0.00072 | Train Acc: 0.985 | Val Acc: 0.972\n",
      "No Improvement: 1\n",
      "Epoch: 22/1000 | Train Loss: 0.00065 | Train Acc: 0.987 | Val Acc: 0.972\n",
      "No Improvement: 2\n",
      "Epoch: 23/1000 | Train Loss: 0.00061 | Train Acc: 0.987 | Val Acc: 0.971\n",
      "No Improvement: 3\n",
      "Epoch: 24/1000 | Train Loss: 0.00059 | Train Acc: 0.987 | Val Acc: 0.971\n",
      "No Improvement: 4\n",
      "Epoch: 25/1000 | Train Loss: 0.00055 | Train Acc: 0.988 | Val Acc: 0.972\n",
      "No Improvement: 5\n",
      "Epoch: 26/1000 | Train Loss: 0.00056 | Train Acc: 0.989 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 27/1000 | Train Loss: 0.00053 | Train Acc: 0.989 | Val Acc: 0.972\n",
      "No Improvement: 7\n",
      "Epoch: 28/1000 | Train Loss: 0.00056 | Train Acc: 0.988 | Val Acc: 0.972\n",
      "No Improvement: 8\n",
      "Epoch: 29/1000 | Train Loss: 0.00051 | Train Acc: 0.990 | Val Acc: 0.970\n",
      "No Improvement: 9\n",
      "Epoch: 30/1000 | Train Loss: 0.00044 | Train Acc: 0.991 | Val Acc: 0.972\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00407 | Train Acc: 0.924 | Val Acc: 0.953\n",
      "Saving Best Model. Test Accuracy: 0.8926\n",
      "Epoch: 1/1000 | Train Loss: 0.00301 | Train Acc: 0.943 | Val Acc: 0.955\n",
      "Saving Best Model. Test Accuracy: 0.8892\n",
      "Epoch: 2/1000 | Train Loss: 0.00261 | Train Acc: 0.949 | Val Acc: 0.958\n",
      "Saving Best Model. Test Accuracy: 0.8973\n",
      "Epoch: 3/1000 | Train Loss: 0.00228 | Train Acc: 0.956 | Val Acc: 0.964\n",
      "Saving Best Model. Test Accuracy: 0.9081\n",
      "Epoch: 4/1000 | Train Loss: 0.00204 | Train Acc: 0.960 | Val Acc: 0.966\n",
      "Saving Best Model. Test Accuracy: 0.9055\n",
      "Epoch: 5/1000 | Train Loss: 0.00186 | Train Acc: 0.964 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.9214\n",
      "Epoch: 6/1000 | Train Loss: 0.00178 | Train Acc: 0.967 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: 0.00164 | Train Acc: 0.968 | Val Acc: 0.964\n",
      "No Improvement: 2\n",
      "Epoch: 8/1000 | Train Loss: 0.00159 | Train Acc: 0.969 | Val Acc: 0.968\n",
      "Saving Best Model. Test Accuracy: 0.9197\n",
      "Epoch: 9/1000 | Train Loss: 0.00141 | Train Acc: 0.971 | Val Acc: 0.968\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: 0.00129 | Train Acc: 0.974 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 11/1000 | Train Loss: 0.00128 | Train Acc: 0.975 | Val Acc: 0.967\n",
      "No Improvement: 3\n",
      "Epoch: 12/1000 | Train Loss: 0.00124 | Train Acc: 0.976 | Val Acc: 0.968\n",
      "No Improvement: 4\n",
      "Epoch: 13/1000 | Train Loss: 0.00116 | Train Acc: 0.977 | Val Acc: 0.968\n",
      "No Improvement: 5\n",
      "Epoch: 14/1000 | Train Loss: 0.00112 | Train Acc: 0.978 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9199\n",
      "Epoch: 15/1000 | Train Loss: 0.00110 | Train Acc: 0.979 | Val Acc: 0.970\n",
      "No Improvement: 1\n",
      "Epoch: 16/1000 | Train Loss: 0.00099 | Train Acc: 0.980 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9251\n",
      "Epoch: 17/1000 | Train Loss: 0.00094 | Train Acc: 0.981 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 18/1000 | Train Loss: 0.00094 | Train Acc: 0.981 | Val Acc: 0.969\n",
      "No Improvement: 2\n",
      "Epoch: 19/1000 | Train Loss: 0.00092 | Train Acc: 0.981 | Val Acc: 0.970\n",
      "No Improvement: 3\n",
      "Epoch: 20/1000 | Train Loss: 0.00089 | Train Acc: 0.982 | Val Acc: 0.970\n",
      "No Improvement: 4\n",
      "Epoch: 21/1000 | Train Loss: 0.00085 | Train Acc: 0.983 | Val Acc: 0.969\n",
      "No Improvement: 5\n",
      "Epoch: 22/1000 | Train Loss: 0.00075 | Train Acc: 0.986 | Val Acc: 0.970\n",
      "No Improvement: 6\n",
      "Epoch: 23/1000 | Train Loss: 0.00079 | Train Acc: 0.984 | Val Acc: 0.970\n",
      "No Improvement: 7\n",
      "Epoch: 24/1000 | Train Loss: 0.00076 | Train Acc: 0.985 | Val Acc: 0.970\n",
      "No Improvement: 8\n",
      "Epoch: 25/1000 | Train Loss: 0.00077 | Train Acc: 0.985 | Val Acc: 0.971\n",
      "No Improvement: 9\n",
      "Epoch: 26/1000 | Train Loss: 0.00071 | Train Acc: 0.986 | Val Acc: 0.971\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00807 | Train Acc: 0.858 | Val Acc: 0.939\n",
      "Saving Best Model. Test Accuracy: 0.8575\n",
      "Epoch: 1/1000 | Train Loss: 0.00626 | Train Acc: 0.890 | Val Acc: 0.952\n",
      "Saving Best Model. Test Accuracy: 0.8801\n",
      "Epoch: 2/1000 | Train Loss: 0.00563 | Train Acc: 0.901 | Val Acc: 0.950\n",
      "No Improvement: 1\n",
      "Epoch: 3/1000 | Train Loss: 0.00527 | Train Acc: 0.910 | Val Acc: 0.952\n",
      "No Improvement: 2\n",
      "Epoch: 4/1000 | Train Loss: 0.00472 | Train Acc: 0.919 | Val Acc: 0.947\n",
      "No Improvement: 3\n",
      "Epoch: 5/1000 | Train Loss: 0.00460 | Train Acc: 0.922 | Val Acc: 0.951\n",
      "No Improvement: 4\n",
      "Epoch: 6/1000 | Train Loss: 0.00449 | Train Acc: 0.922 | Val Acc: 0.958\n",
      "Saving Best Model. Test Accuracy: 0.8893\n",
      "Epoch: 7/1000 | Train Loss: 0.00409 | Train Acc: 0.931 | Val Acc: 0.957\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00402 | Train Acc: 0.932 | Val Acc: 0.960\n",
      "Saving Best Model. Test Accuracy: 0.8944\n",
      "Epoch: 9/1000 | Train Loss: 0.00389 | Train Acc: 0.933 | Val Acc: 0.961\n",
      "Saving Best Model. Test Accuracy: 0.898\n",
      "Epoch: 10/1000 | Train Loss: 0.00400 | Train Acc: 0.931 | Val Acc: 0.954\n",
      "No Improvement: 1\n",
      "Epoch: 11/1000 | Train Loss: 0.00376 | Train Acc: 0.935 | Val Acc: 0.966\n",
      "Saving Best Model. Test Accuracy: 0.9073\n",
      "Epoch: 12/1000 | Train Loss: 0.00363 | Train Acc: 0.937 | Val Acc: 0.964\n",
      "No Improvement: 1\n",
      "Epoch: 13/1000 | Train Loss: 0.00364 | Train Acc: 0.938 | Val Acc: 0.964\n",
      "No Improvement: 2\n",
      "Epoch: 14/1000 | Train Loss: 0.00356 | Train Acc: 0.939 | Val Acc: 0.965\n",
      "No Improvement: 3\n",
      "Epoch: 15/1000 | Train Loss: 0.00341 | Train Acc: 0.940 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9099\n",
      "Epoch: 16/1000 | Train Loss: 0.00312 | Train Acc: 0.946 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 17/1000 | Train Loss: 0.00314 | Train Acc: 0.945 | Val Acc: 0.965\n",
      "No Improvement: 2\n",
      "Epoch: 18/1000 | Train Loss: 0.00315 | Train Acc: 0.946 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 19/1000 | Train Loss: 0.00301 | Train Acc: 0.948 | Val Acc: 0.969\n",
      "No Improvement: 4\n",
      "Epoch: 20/1000 | Train Loss: 0.00303 | Train Acc: 0.948 | Val Acc: 0.969\n",
      "No Improvement: 5\n",
      "Epoch: 21/1000 | Train Loss: 0.00301 | Train Acc: 0.949 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 22/1000 | Train Loss: 0.00280 | Train Acc: 0.952 | Val Acc: 0.966\n",
      "No Improvement: 7\n",
      "Epoch: 23/1000 | Train Loss: 0.00271 | Train Acc: 0.954 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9199\n",
      "Epoch: 24/1000 | Train Loss: 0.00283 | Train Acc: 0.952 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 25/1000 | Train Loss: 0.00266 | Train Acc: 0.954 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 26/1000 | Train Loss: 0.00282 | Train Acc: 0.952 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 27/1000 | Train Loss: 0.00267 | Train Acc: 0.955 | Val Acc: 0.969\n",
      "No Improvement: 4\n",
      "Epoch: 28/1000 | Train Loss: 0.00269 | Train Acc: 0.955 | Val Acc: 0.969\n",
      "No Improvement: 5\n",
      "Epoch: 29/1000 | Train Loss: 0.00239 | Train Acc: 0.958 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 30/1000 | Train Loss: 0.00246 | Train Acc: 0.958 | Val Acc: 0.969\n",
      "No Improvement: 7\n",
      "Epoch: 31/1000 | Train Loss: 0.00259 | Train Acc: 0.957 | Val Acc: 0.967\n",
      "No Improvement: 8\n",
      "Epoch: 32/1000 | Train Loss: 0.00249 | Train Acc: 0.958 | Val Acc: 0.966\n",
      "No Improvement: 9\n",
      "Epoch: 33/1000 | Train Loss: 0.00242 | Train Acc: 0.960 | Val Acc: 0.971\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.49193 | Train Acc: 0.962 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.9156\n",
      "Epoch: 1/1000 | Train Loss: -1.26226 | Train Acc: 0.934 | Val Acc: 0.959\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -2.46219 | Train Acc: 0.911 | Val Acc: 0.947\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -4.09256 | Train Acc: 0.891 | Val Acc: 0.940\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -6.12592 | Train Acc: 0.878 | Val Acc: 0.938\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -8.54308 | Train Acc: 0.866 | Val Acc: 0.929\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -11.35306 | Train Acc: 0.862 | Val Acc: 0.925\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -14.54026 | Train Acc: 0.859 | Val Acc: 0.929\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -18.08276 | Train Acc: 0.855 | Val Acc: 0.917\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -21.97387 | Train Acc: 0.847 | Val Acc: 0.909\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -26.31548 | Train Acc: 0.840 | Val Acc: 0.918\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -57.81704 | Train Acc: 0.786 | Val Acc: 0.834\n",
      "Saving Best Model. Test Accuracy: 0.7712\n",
      "Epoch: 1/1000 | Train Loss: -157.18068 | Train Acc: 0.683 | Val Acc: 0.740\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -318.82508 | Train Acc: 0.607 | Val Acc: 0.716\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -537.34068 | Train Acc: 0.539 | Val Acc: 0.687\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -809.03918 | Train Acc: 0.557 | Val Acc: 0.880\n",
      "Saving Best Model. Test Accuracy: 0.7906\n",
      "Epoch: 5/1000 | Train Loss: -1131.47319 | Train Acc: 0.530 | Val Acc: 0.785\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: -1503.74724 | Train Acc: 0.476 | Val Acc: 0.580\n",
      "No Improvement: 2\n",
      "Epoch: 7/1000 | Train Loss: -1920.38035 | Train Acc: 0.449 | Val Acc: 0.497\n",
      "No Improvement: 3\n",
      "Epoch: 8/1000 | Train Loss: -2388.82447 | Train Acc: 0.400 | Val Acc: 0.463\n",
      "No Improvement: 4\n",
      "Epoch: 9/1000 | Train Loss: -2905.97921 | Train Acc: 0.399 | Val Acc: 0.463\n",
      "No Improvement: 5\n",
      "Epoch: 10/1000 | Train Loss: -3474.92438 | Train Acc: 0.395 | Val Acc: 0.458\n",
      "No Improvement: 6\n",
      "Epoch: 11/1000 | Train Loss: -4089.10842 | Train Acc: 0.417 | Val Acc: 0.457\n",
      "No Improvement: 7\n",
      "Epoch: 12/1000 | Train Loss: -4744.47763 | Train Acc: 0.408 | Val Acc: 0.465\n",
      "No Improvement: 8\n",
      "Epoch: 13/1000 | Train Loss: -5442.89196 | Train Acc: 0.405 | Val Acc: 0.469\n",
      "No Improvement: 9\n",
      "Epoch: 14/1000 | Train Loss: -6193.22769 | Train Acc: 0.391 | Val Acc: 0.461\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -11262.63877 | Train Acc: 0.223 | Val Acc: 0.099\n",
      "Saving Best Model. Test Accuracy: 0.1\n",
      "Epoch: 1/1000 | Train Loss: -25431.46912 | Train Acc: 0.129 | Val Acc: 0.099\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -46607.63319 | Train Acc: 0.198 | Val Acc: 0.267\n",
      "Saving Best Model. Test Accuracy: 0.2308\n",
      "Epoch: 3/1000 | Train Loss: -74304.90840 | Train Acc: 0.196 | Val Acc: 0.465\n",
      "Saving Best Model. Test Accuracy: 0.4115\n",
      "Epoch: 4/1000 | Train Loss: -107868.33995 | Train Acc: 0.392 | Val Acc: 0.367\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: -147626.56796 | Train Acc: 0.229 | Val Acc: 0.194\n",
      "No Improvement: 2\n",
      "Epoch: 6/1000 | Train Loss: -192745.71512 | Train Acc: 0.133 | Val Acc: 0.099\n",
      "No Improvement: 3\n",
      "Epoch: 7/1000 | Train Loss: -242778.45254 | Train Acc: 0.158 | Val Acc: 0.179\n",
      "No Improvement: 4\n",
      "Epoch: 8/1000 | Train Loss: -297550.59673 | Train Acc: 0.172 | Val Acc: 0.183\n",
      "No Improvement: 5\n",
      "Epoch: 9/1000 | Train Loss: -357171.26658 | Train Acc: 0.166 | Val Acc: 0.179\n",
      "No Improvement: 6\n",
      "Epoch: 10/1000 | Train Loss: -422991.83612 | Train Acc: 0.183 | Val Acc: 0.173\n",
      "No Improvement: 7\n",
      "Epoch: 11/1000 | Train Loss: -491409.22371 | Train Acc: 0.162 | Val Acc: 0.161\n",
      "No Improvement: 8\n",
      "Epoch: 12/1000 | Train Loss: -567032.17254 | Train Acc: 0.144 | Val Acc: 0.165\n",
      "No Improvement: 9\n",
      "Epoch: 13/1000 | Train Loss: -647051.22192 | Train Acc: 0.154 | Val Acc: 0.140\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00854 | Train Acc: 0.839 | Val Acc: 0.924\n",
      "Saving Best Model. Test Accuracy: 0.8376\n",
      "Epoch: 1/1000 | Train Loss: 0.00473 | Train Acc: 0.910 | Val Acc: 0.943\n",
      "Saving Best Model. Test Accuracy: 0.8639\n",
      "Epoch: 2/1000 | Train Loss: 0.00371 | Train Acc: 0.929 | Val Acc: 0.949\n",
      "Saving Best Model. Test Accuracy: 0.8826\n",
      "Epoch: 3/1000 | Train Loss: 0.00319 | Train Acc: 0.940 | Val Acc: 0.957\n",
      "Saving Best Model. Test Accuracy: 0.9007\n",
      "Epoch: 4/1000 | Train Loss: 0.00266 | Train Acc: 0.949 | Val Acc: 0.956\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 0.00247 | Train Acc: 0.954 | Val Acc: 0.960\n",
      "Saving Best Model. Test Accuracy: 0.8976\n",
      "Epoch: 6/1000 | Train Loss: 0.00211 | Train Acc: 0.959 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.909\n",
      "Epoch: 7/1000 | Train Loss: 0.00201 | Train Acc: 0.961 | Val Acc: 0.964\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00177 | Train Acc: 0.966 | Val Acc: 0.965\n",
      "No Improvement: 2\n",
      "Epoch: 9/1000 | Train Loss: 0.00160 | Train Acc: 0.969 | Val Acc: 0.965\n",
      "No Improvement: 3\n",
      "Epoch: 10/1000 | Train Loss: 0.00149 | Train Acc: 0.971 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9172\n",
      "Epoch: 11/1000 | Train Loss: 0.00140 | Train Acc: 0.973 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 12/1000 | Train Loss: 0.00133 | Train Acc: 0.973 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 13/1000 | Train Loss: 0.00117 | Train Acc: 0.977 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9207\n",
      "Epoch: 14/1000 | Train Loss: 0.00110 | Train Acc: 0.977 | Val Acc: 0.968\n",
      "No Improvement: 1\n",
      "Epoch: 15/1000 | Train Loss: 0.00107 | Train Acc: 0.979 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 16/1000 | Train Loss: 0.00101 | Train Acc: 0.980 | Val Acc: 0.968\n",
      "No Improvement: 3\n",
      "Epoch: 17/1000 | Train Loss: 0.00089 | Train Acc: 0.982 | Val Acc: 0.968\n",
      "No Improvement: 4\n",
      "Epoch: 18/1000 | Train Loss: 0.00091 | Train Acc: 0.982 | Val Acc: 0.969\n",
      "No Improvement: 5\n",
      "Epoch: 19/1000 | Train Loss: 0.00077 | Train Acc: 0.985 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9236\n",
      "Epoch: 20/1000 | Train Loss: 0.00084 | Train Acc: 0.983 | Val Acc: 0.971\n",
      "No Improvement: 1\n",
      "Epoch: 21/1000 | Train Loss: 0.00073 | Train Acc: 0.985 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 22/1000 | Train Loss: 0.00073 | Train Acc: 0.985 | Val Acc: 0.972\n",
      "Saving Best Model. Test Accuracy: 0.9284\n",
      "Epoch: 23/1000 | Train Loss: 0.00069 | Train Acc: 0.986 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 24/1000 | Train Loss: 0.00068 | Train Acc: 0.986 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 25/1000 | Train Loss: 0.00063 | Train Acc: 0.987 | Val Acc: 0.973\n",
      "Saving Best Model. Test Accuracy: 0.9221\n",
      "Epoch: 26/1000 | Train Loss: 0.00064 | Train Acc: 0.987 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 27/1000 | Train Loss: 0.00059 | Train Acc: 0.988 | Val Acc: 0.971\n",
      "No Improvement: 2\n",
      "Epoch: 28/1000 | Train Loss: 0.00058 | Train Acc: 0.988 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 29/1000 | Train Loss: 0.00055 | Train Acc: 0.989 | Val Acc: 0.974\n",
      "Saving Best Model. Test Accuracy: 0.9244\n",
      "Epoch: 30/1000 | Train Loss: 0.00051 | Train Acc: 0.990 | Val Acc: 0.973\n",
      "No Improvement: 1\n",
      "Epoch: 31/1000 | Train Loss: 0.00054 | Train Acc: 0.989 | Val Acc: 0.972\n",
      "No Improvement: 2\n",
      "Epoch: 32/1000 | Train Loss: 0.00047 | Train Acc: 0.990 | Val Acc: 0.974\n",
      "No Improvement: 3\n",
      "Epoch: 33/1000 | Train Loss: 0.00049 | Train Acc: 0.991 | Val Acc: 0.973\n",
      "No Improvement: 4\n",
      "Epoch: 34/1000 | Train Loss: 0.00047 | Train Acc: 0.990 | Val Acc: 0.971\n",
      "No Improvement: 5\n",
      "Epoch: 35/1000 | Train Loss: 0.00047 | Train Acc: 0.991 | Val Acc: 0.972\n",
      "No Improvement: 6\n",
      "Epoch: 36/1000 | Train Loss: 0.00045 | Train Acc: 0.991 | Val Acc: 0.971\n",
      "No Improvement: 7\n",
      "Epoch: 37/1000 | Train Loss: 0.00046 | Train Acc: 0.990 | Val Acc: 0.975\n",
      "Saving Best Model. Test Accuracy: 0.9273\n",
      "Epoch: 38/1000 | Train Loss: 0.00041 | Train Acc: 0.991 | Val Acc: 0.974\n",
      "No Improvement: 1\n",
      "Epoch: 39/1000 | Train Loss: 0.00040 | Train Acc: 0.992 | Val Acc: 0.974\n",
      "No Improvement: 2\n",
      "Epoch: 40/1000 | Train Loss: 0.00042 | Train Acc: 0.991 | Val Acc: 0.973\n",
      "No Improvement: 3\n",
      "Epoch: 41/1000 | Train Loss: 0.00041 | Train Acc: 0.992 | Val Acc: 0.974\n",
      "No Improvement: 4\n",
      "Epoch: 42/1000 | Train Loss: 0.00037 | Train Acc: 0.992 | Val Acc: 0.974\n",
      "No Improvement: 5\n",
      "Epoch: 43/1000 | Train Loss: 0.00040 | Train Acc: 0.992 | Val Acc: 0.973\n",
      "No Improvement: 6\n",
      "Epoch: 44/1000 | Train Loss: 0.00036 | Train Acc: 0.993 | Val Acc: 0.975\n",
      "No Improvement: 7\n",
      "Epoch: 45/1000 | Train Loss: 0.00033 | Train Acc: 0.993 | Val Acc: 0.975\n",
      "No Improvement: 8\n",
      "Epoch: 46/1000 | Train Loss: 0.00034 | Train Acc: 0.993 | Val Acc: 0.974\n",
      "No Improvement: 9\n",
      "Epoch: 47/1000 | Train Loss: 0.00034 | Train Acc: 0.993 | Val Acc: 0.976\n",
      "Saving Best Model. Test Accuracy: 0.9247\n",
      "Epoch: 48/1000 | Train Loss: 0.00034 | Train Acc: 0.993 | Val Acc: 0.973\n",
      "No Improvement: 1\n",
      "Epoch: 49/1000 | Train Loss: 0.00036 | Train Acc: 0.993 | Val Acc: 0.975\n",
      "No Improvement: 2\n",
      "Epoch: 50/1000 | Train Loss: 0.00030 | Train Acc: 0.994 | Val Acc: 0.975\n",
      "No Improvement: 3\n",
      "Epoch: 51/1000 | Train Loss: 0.00032 | Train Acc: 0.994 | Val Acc: 0.975\n",
      "No Improvement: 4\n",
      "Epoch: 52/1000 | Train Loss: 0.00031 | Train Acc: 0.994 | Val Acc: 0.974\n",
      "No Improvement: 5\n",
      "Epoch: 53/1000 | Train Loss: 0.00031 | Train Acc: 0.994 | Val Acc: 0.974\n",
      "No Improvement: 6\n",
      "Epoch: 54/1000 | Train Loss: 0.00032 | Train Acc: 0.993 | Val Acc: 0.973\n",
      "No Improvement: 7\n",
      "Epoch: 55/1000 | Train Loss: 0.00029 | Train Acc: 0.994 | Val Acc: 0.975\n",
      "No Improvement: 8\n",
      "Epoch: 56/1000 | Train Loss: 0.00030 | Train Acc: 0.994 | Val Acc: 0.974\n",
      "No Improvement: 9\n",
      "Epoch: 57/1000 | Train Loss: 0.00030 | Train Acc: 0.994 | Val Acc: 0.976\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00349 | Train Acc: 0.935 | Val Acc: 0.953\n",
      "Saving Best Model. Test Accuracy: 0.8861\n",
      "Epoch: 1/1000 | Train Loss: 0.00275 | Train Acc: 0.948 | Val Acc: 0.962\n",
      "Saving Best Model. Test Accuracy: 0.8968\n",
      "Epoch: 2/1000 | Train Loss: 0.00240 | Train Acc: 0.954 | Val Acc: 0.964\n",
      "Saving Best Model. Test Accuracy: 0.9092\n",
      "Epoch: 3/1000 | Train Loss: 0.00217 | Train Acc: 0.958 | Val Acc: 0.961\n",
      "No Improvement: 1\n",
      "Epoch: 4/1000 | Train Loss: 0.00204 | Train Acc: 0.962 | Val Acc: 0.963\n",
      "No Improvement: 2\n",
      "Epoch: 5/1000 | Train Loss: 0.00183 | Train Acc: 0.965 | Val Acc: 0.964\n",
      "No Improvement: 3\n",
      "Epoch: 6/1000 | Train Loss: 0.00166 | Train Acc: 0.968 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9168\n",
      "Epoch: 7/1000 | Train Loss: 0.00161 | Train Acc: 0.969 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00151 | Train Acc: 0.971 | Val Acc: 0.965\n",
      "No Improvement: 2\n",
      "Epoch: 9/1000 | Train Loss: 0.00142 | Train Acc: 0.972 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 10/1000 | Train Loss: 0.00136 | Train Acc: 0.974 | Val Acc: 0.968\n",
      "No Improvement: 4\n",
      "Epoch: 11/1000 | Train Loss: 0.00130 | Train Acc: 0.974 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.9162\n",
      "Epoch: 12/1000 | Train Loss: 0.00126 | Train Acc: 0.977 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9238\n",
      "Epoch: 13/1000 | Train Loss: 0.00112 | Train Acc: 0.979 | Val Acc: 0.968\n",
      "No Improvement: 1\n",
      "Epoch: 14/1000 | Train Loss: 0.00108 | Train Acc: 0.979 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 15/1000 | Train Loss: 0.00107 | Train Acc: 0.980 | Val Acc: 0.971\n",
      "No Improvement: 3\n",
      "Epoch: 16/1000 | Train Loss: 0.00104 | Train Acc: 0.981 | Val Acc: 0.970\n",
      "No Improvement: 4\n",
      "Epoch: 17/1000 | Train Loss: 0.00101 | Train Acc: 0.980 | Val Acc: 0.971\n",
      "No Improvement: 5\n",
      "Epoch: 18/1000 | Train Loss: 0.00093 | Train Acc: 0.982 | Val Acc: 0.971\n",
      "No Improvement: 6\n",
      "Epoch: 19/1000 | Train Loss: 0.00090 | Train Acc: 0.982 | Val Acc: 0.972\n",
      "Saving Best Model. Test Accuracy: 0.9242\n",
      "Epoch: 20/1000 | Train Loss: 0.00087 | Train Acc: 0.983 | Val Acc: 0.973\n",
      "Saving Best Model. Test Accuracy: 0.9297\n",
      "Epoch: 21/1000 | Train Loss: 0.00083 | Train Acc: 0.984 | Val Acc: 0.969\n",
      "No Improvement: 1\n",
      "Epoch: 22/1000 | Train Loss: 0.00085 | Train Acc: 0.983 | Val Acc: 0.971\n",
      "No Improvement: 2\n",
      "Epoch: 23/1000 | Train Loss: 0.00083 | Train Acc: 0.984 | Val Acc: 0.971\n",
      "No Improvement: 3\n",
      "Epoch: 24/1000 | Train Loss: 0.00079 | Train Acc: 0.984 | Val Acc: 0.972\n",
      "No Improvement: 4\n",
      "Epoch: 25/1000 | Train Loss: 0.00076 | Train Acc: 0.985 | Val Acc: 0.973\n",
      "No Improvement: 5\n",
      "Epoch: 26/1000 | Train Loss: 0.00071 | Train Acc: 0.986 | Val Acc: 0.973\n",
      "No Improvement: 6\n",
      "Epoch: 27/1000 | Train Loss: 0.00071 | Train Acc: 0.986 | Val Acc: 0.971\n",
      "No Improvement: 7\n",
      "Epoch: 28/1000 | Train Loss: 0.00076 | Train Acc: 0.986 | Val Acc: 0.972\n",
      "No Improvement: 8\n",
      "Epoch: 29/1000 | Train Loss: 0.00060 | Train Acc: 0.988 | Val Acc: 0.973\n",
      "No Improvement: 9\n",
      "Epoch: 30/1000 | Train Loss: 0.00066 | Train Acc: 0.988 | Val Acc: 0.975\n",
      "Saving Best Model. Test Accuracy: 0.9268\n",
      "Epoch: 31/1000 | Train Loss: 0.00063 | Train Acc: 0.988 | Val Acc: 0.974\n",
      "No Improvement: 1\n",
      "Epoch: 32/1000 | Train Loss: 0.00065 | Train Acc: 0.987 | Val Acc: 0.973\n",
      "No Improvement: 2\n",
      "Epoch: 33/1000 | Train Loss: 0.00060 | Train Acc: 0.988 | Val Acc: 0.972\n",
      "No Improvement: 3\n",
      "Epoch: 34/1000 | Train Loss: 0.00060 | Train Acc: 0.988 | Val Acc: 0.972\n",
      "No Improvement: 4\n",
      "Epoch: 35/1000 | Train Loss: 0.00061 | Train Acc: 0.988 | Val Acc: 0.971\n",
      "No Improvement: 5\n",
      "Epoch: 36/1000 | Train Loss: 0.00059 | Train Acc: 0.989 | Val Acc: 0.973\n",
      "No Improvement: 6\n",
      "Epoch: 37/1000 | Train Loss: 0.00062 | Train Acc: 0.989 | Val Acc: 0.973\n",
      "No Improvement: 7\n",
      "Epoch: 38/1000 | Train Loss: 0.00053 | Train Acc: 0.990 | Val Acc: 0.975\n",
      "No Improvement: 8\n",
      "Epoch: 39/1000 | Train Loss: 0.00057 | Train Acc: 0.990 | Val Acc: 0.973\n",
      "No Improvement: 9\n",
      "Epoch: 40/1000 | Train Loss: 0.00054 | Train Acc: 0.990 | Val Acc: 0.971\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00749 | Train Acc: 0.871 | Val Acc: 0.940\n",
      "Saving Best Model. Test Accuracy: 0.8529\n",
      "Epoch: 1/1000 | Train Loss: 0.00629 | Train Acc: 0.894 | Val Acc: 0.946\n",
      "Saving Best Model. Test Accuracy: 0.8715\n",
      "Epoch: 2/1000 | Train Loss: 0.00557 | Train Acc: 0.904 | Val Acc: 0.949\n",
      "Saving Best Model. Test Accuracy: 0.8745\n",
      "Epoch: 3/1000 | Train Loss: 0.00506 | Train Acc: 0.914 | Val Acc: 0.949\n",
      "No Improvement: 1\n",
      "Epoch: 4/1000 | Train Loss: 0.00478 | Train Acc: 0.921 | Val Acc: 0.957\n",
      "Saving Best Model. Test Accuracy: 0.8882\n",
      "Epoch: 5/1000 | Train Loss: 0.00440 | Train Acc: 0.925 | Val Acc: 0.953\n",
      "No Improvement: 1\n",
      "Epoch: 6/1000 | Train Loss: 0.00445 | Train Acc: 0.924 | Val Acc: 0.959\n",
      "Saving Best Model. Test Accuracy: 0.8969\n",
      "Epoch: 7/1000 | Train Loss: 0.00418 | Train Acc: 0.929 | Val Acc: 0.957\n",
      "No Improvement: 1\n",
      "Epoch: 8/1000 | Train Loss: 0.00383 | Train Acc: 0.934 | Val Acc: 0.960\n",
      "Saving Best Model. Test Accuracy: 0.9018\n",
      "Epoch: 9/1000 | Train Loss: 0.00380 | Train Acc: 0.936 | Val Acc: 0.958\n",
      "No Improvement: 1\n",
      "Epoch: 10/1000 | Train Loss: 0.00359 | Train Acc: 0.938 | Val Acc: 0.961\n",
      "Saving Best Model. Test Accuracy: 0.9049\n",
      "Epoch: 11/1000 | Train Loss: 0.00362 | Train Acc: 0.939 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.9083\n",
      "Epoch: 12/1000 | Train Loss: 0.00329 | Train Acc: 0.945 | Val Acc: 0.965\n",
      "No Improvement: 1\n",
      "Epoch: 13/1000 | Train Loss: 0.00337 | Train Acc: 0.943 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.91\n",
      "Epoch: 14/1000 | Train Loss: 0.00322 | Train Acc: 0.945 | Val Acc: 0.968\n",
      "No Improvement: 1\n",
      "Epoch: 15/1000 | Train Loss: 0.00288 | Train Acc: 0.951 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 16/1000 | Train Loss: 0.00305 | Train Acc: 0.946 | Val Acc: 0.964\n",
      "No Improvement: 3\n",
      "Epoch: 17/1000 | Train Loss: 0.00316 | Train Acc: 0.946 | Val Acc: 0.966\n",
      "No Improvement: 4\n",
      "Epoch: 18/1000 | Train Loss: 0.00306 | Train Acc: 0.947 | Val Acc: 0.965\n",
      "No Improvement: 5\n",
      "Epoch: 19/1000 | Train Loss: 0.00287 | Train Acc: 0.952 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 20/1000 | Train Loss: 0.00274 | Train Acc: 0.953 | Val Acc: 0.966\n",
      "No Improvement: 7\n",
      "Epoch: 21/1000 | Train Loss: 0.00273 | Train Acc: 0.954 | Val Acc: 0.970\n",
      "Saving Best Model. Test Accuracy: 0.918\n",
      "Epoch: 22/1000 | Train Loss: 0.00279 | Train Acc: 0.953 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 23/1000 | Train Loss: 0.00255 | Train Acc: 0.957 | Val Acc: 0.968\n",
      "No Improvement: 2\n",
      "Epoch: 24/1000 | Train Loss: 0.00256 | Train Acc: 0.957 | Val Acc: 0.970\n",
      "No Improvement: 3\n",
      "Epoch: 25/1000 | Train Loss: 0.00258 | Train Acc: 0.956 | Val Acc: 0.969\n",
      "No Improvement: 4\n",
      "Epoch: 26/1000 | Train Loss: 0.00249 | Train Acc: 0.959 | Val Acc: 0.968\n",
      "No Improvement: 5\n",
      "Epoch: 27/1000 | Train Loss: 0.00243 | Train Acc: 0.958 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9153\n",
      "Epoch: 28/1000 | Train Loss: 0.00253 | Train Acc: 0.959 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 29/1000 | Train Loss: 0.00227 | Train Acc: 0.962 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 30/1000 | Train Loss: 0.00243 | Train Acc: 0.962 | Val Acc: 0.971\n",
      "No Improvement: 3\n",
      "Epoch: 31/1000 | Train Loss: 0.00232 | Train Acc: 0.961 | Val Acc: 0.971\n",
      "No Improvement: 4\n",
      "Epoch: 32/1000 | Train Loss: 0.00215 | Train Acc: 0.963 | Val Acc: 0.972\n",
      "Saving Best Model. Test Accuracy: 0.9183\n",
      "Epoch: 33/1000 | Train Loss: 0.00222 | Train Acc: 0.962 | Val Acc: 0.973\n",
      "Saving Best Model. Test Accuracy: 0.9233\n",
      "Epoch: 34/1000 | Train Loss: 0.00218 | Train Acc: 0.964 | Val Acc: 0.972\n",
      "No Improvement: 1\n",
      "Epoch: 35/1000 | Train Loss: 0.00215 | Train Acc: 0.964 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 36/1000 | Train Loss: 0.00215 | Train Acc: 0.965 | Val Acc: 0.972\n",
      "No Improvement: 3\n",
      "Epoch: 37/1000 | Train Loss: 0.00217 | Train Acc: 0.964 | Val Acc: 0.970\n",
      "No Improvement: 4\n",
      "Epoch: 38/1000 | Train Loss: 0.00209 | Train Acc: 0.964 | Val Acc: 0.970\n",
      "No Improvement: 5\n",
      "Epoch: 39/1000 | Train Loss: 0.00237 | Train Acc: 0.959 | Val Acc: 0.970\n",
      "No Improvement: 6\n",
      "Epoch: 40/1000 | Train Loss: 0.00231 | Train Acc: 0.961 | Val Acc: 0.971\n",
      "No Improvement: 7\n",
      "Epoch: 41/1000 | Train Loss: 0.00213 | Train Acc: 0.965 | Val Acc: 0.974\n",
      "Saving Best Model. Test Accuracy: 0.9241\n",
      "Epoch: 42/1000 | Train Loss: 0.00198 | Train Acc: 0.966 | Val Acc: 0.973\n",
      "No Improvement: 1\n",
      "Epoch: 43/1000 | Train Loss: 0.00204 | Train Acc: 0.966 | Val Acc: 0.973\n",
      "No Improvement: 2\n",
      "Epoch: 44/1000 | Train Loss: 0.00217 | Train Acc: 0.964 | Val Acc: 0.971\n",
      "No Improvement: 3\n",
      "Epoch: 45/1000 | Train Loss: 0.00222 | Train Acc: 0.963 | Val Acc: 0.971\n",
      "No Improvement: 4\n",
      "Epoch: 46/1000 | Train Loss: 0.00221 | Train Acc: 0.963 | Val Acc: 0.972\n",
      "No Improvement: 5\n",
      "Epoch: 47/1000 | Train Loss: 0.00202 | Train Acc: 0.965 | Val Acc: 0.972\n",
      "No Improvement: 6\n",
      "Epoch: 48/1000 | Train Loss: 0.00205 | Train Acc: 0.966 | Val Acc: 0.971\n",
      "No Improvement: 7\n",
      "Epoch: 49/1000 | Train Loss: 0.00217 | Train Acc: 0.963 | Val Acc: 0.973\n",
      "No Improvement: 8\n",
      "Epoch: 50/1000 | Train Loss: 0.00197 | Train Acc: 0.967 | Val Acc: 0.972\n",
      "No Improvement: 9\n",
      "Epoch: 51/1000 | Train Loss: 0.00192 | Train Acc: 0.967 | Val Acc: 0.973\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.71001 | Train Acc: 0.975 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9217\n",
      "Epoch: 1/1000 | Train Loss: -1.63718 | Train Acc: 0.959 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -3.05078 | Train Acc: 0.945 | Val Acc: 0.962\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -4.89545 | Train Acc: 0.931 | Val Acc: 0.958\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -7.14345 | Train Acc: 0.919 | Val Acc: 0.952\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -9.77958 | Train Acc: 0.910 | Val Acc: 0.951\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -12.80198 | Train Acc: 0.901 | Val Acc: 0.951\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -16.14052 | Train Acc: 0.885 | Val Acc: 0.945\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -19.85744 | Train Acc: 0.878 | Val Acc: 0.933\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -23.92330 | Train Acc: 0.868 | Val Acc: 0.937\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -28.31449 | Train Acc: 0.860 | Val Acc: 0.931\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -60.52347 | Train Acc: 0.796 | Val Acc: 0.866\n",
      "Saving Best Model. Test Accuracy: 0.7841\n",
      "Epoch: 1/1000 | Train Loss: -160.62340 | Train Acc: 0.642 | Val Acc: 0.677\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -321.00614 | Train Acc: 0.497 | Val Acc: 0.471\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -538.43348 | Train Acc: 0.452 | Val Acc: 0.543\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -803.59011 | Train Acc: 0.463 | Val Acc: 0.580\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -1112.53680 | Train Acc: 0.451 | Val Acc: 0.553\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -1475.05964 | Train Acc: 0.438 | Val Acc: 0.543\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -1876.20280 | Train Acc: 0.432 | Val Acc: 0.472\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -2321.30194 | Train Acc: 0.452 | Val Acc: 0.477\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -2809.60909 | Train Acc: 0.445 | Val Acc: 0.479\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -3340.97880 | Train Acc: 0.447 | Val Acc: 0.476\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -7178.64347 | Train Acc: 0.438 | Val Acc: 0.547\n",
      "Saving Best Model. Test Accuracy: 0.4948\n",
      "Epoch: 1/1000 | Train Loss: -18757.10561 | Train Acc: 0.431 | Val Acc: 0.472\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -37121.02336 | Train Acc: 0.423 | Val Acc: 0.568\n",
      "Saving Best Model. Test Accuracy: 0.5232\n",
      "Epoch: 3/1000 | Train Loss: -61430.46491 | Train Acc: 0.536 | Val Acc: 0.572\n",
      "Saving Best Model. Test Accuracy: 0.5295\n",
      "Epoch: 4/1000 | Train Loss: -90974.27393 | Train Acc: 0.450 | Val Acc: 0.568\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: -125389.13257 | Train Acc: 0.429 | Val Acc: 0.570\n",
      "No Improvement: 2\n",
      "Epoch: 6/1000 | Train Loss: -164160.65406 | Train Acc: 0.482 | Val Acc: 0.477\n",
      "No Improvement: 3\n",
      "Epoch: 7/1000 | Train Loss: -207461.89300 | Train Acc: 0.398 | Val Acc: 0.383\n",
      "No Improvement: 4\n",
      "Epoch: 8/1000 | Train Loss: -255121.61871 | Train Acc: 0.385 | Val Acc: 0.383\n",
      "No Improvement: 5\n",
      "Epoch: 9/1000 | Train Loss: -306512.40050 | Train Acc: 0.374 | Val Acc: 0.382\n",
      "No Improvement: 6\n",
      "Epoch: 10/1000 | Train Loss: -362608.19904 | Train Acc: 0.356 | Val Acc: 0.382\n",
      "No Improvement: 7\n",
      "Epoch: 11/1000 | Train Loss: -422013.89621 | Train Acc: 0.400 | Val Acc: 0.475\n",
      "No Improvement: 8\n",
      "Epoch: 12/1000 | Train Loss: -485739.51579 | Train Acc: 0.391 | Val Acc: 0.477\n",
      "No Improvement: 9\n",
      "Epoch: 13/1000 | Train Loss: -553509.89179 | Train Acc: 0.443 | Val Acc: 0.477\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00813 | Train Acc: 0.843 | Val Acc: 0.925\n",
      "Saving Best Model. Test Accuracy: 0.8357\n",
      "Epoch: 1/1000 | Train Loss: 0.00472 | Train Acc: 0.909 | Val Acc: 0.945\n",
      "Saving Best Model. Test Accuracy: 0.8578\n",
      "Epoch: 2/1000 | Train Loss: 0.00375 | Train Acc: 0.927 | Val Acc: 0.948\n",
      "Saving Best Model. Test Accuracy: 0.8805\n",
      "Epoch: 3/1000 | Train Loss: 0.00314 | Train Acc: 0.939 | Val Acc: 0.959\n",
      "Saving Best Model. Test Accuracy: 0.8859\n",
      "Epoch: 4/1000 | Train Loss: 0.00272 | Train Acc: 0.947 | Val Acc: 0.953\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 0.00248 | Train Acc: 0.952 | Val Acc: 0.962\n",
      "Saving Best Model. Test Accuracy: 0.9039\n",
      "Epoch: 6/1000 | Train Loss: 0.00213 | Train Acc: 0.958 | Val Acc: 0.962\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: 0.00199 | Train Acc: 0.961 | Val Acc: 0.963\n",
      "Saving Best Model. Test Accuracy: 0.9069\n",
      "Epoch: 8/1000 | Train Loss: 0.00179 | Train Acc: 0.965 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.9072\n",
      "Epoch: 9/1000 | Train Loss: 0.00166 | Train Acc: 0.967 | Val Acc: 0.967\n",
      "Saving Best Model. Test Accuracy: 0.919\n",
      "Epoch: 10/1000 | Train Loss: 0.00154 | Train Acc: 0.970 | Val Acc: 0.965\n",
      "No Improvement: 1\n",
      "Epoch: 11/1000 | Train Loss: 0.00139 | Train Acc: 0.972 | Val Acc: 0.968\n",
      "Saving Best Model. Test Accuracy: 0.9164\n",
      "Epoch: 12/1000 | Train Loss: 0.00128 | Train Acc: 0.974 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9186\n",
      "Epoch: 13/1000 | Train Loss: 0.00123 | Train Acc: 0.975 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9191\n",
      "Epoch: 14/1000 | Train Loss: 0.00107 | Train Acc: 0.978 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 15/1000 | Train Loss: 0.00106 | Train Acc: 0.979 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 16/1000 | Train Loss: 0.00099 | Train Acc: 0.980 | Val Acc: 0.968\n",
      "No Improvement: 3\n",
      "Epoch: 17/1000 | Train Loss: 0.00093 | Train Acc: 0.982 | Val Acc: 0.970\n",
      "No Improvement: 4\n",
      "Epoch: 18/1000 | Train Loss: 0.00090 | Train Acc: 0.981 | Val Acc: 0.970\n",
      "No Improvement: 5\n",
      "Epoch: 19/1000 | Train Loss: 0.00077 | Train Acc: 0.985 | Val Acc: 0.969\n",
      "No Improvement: 6\n",
      "Epoch: 20/1000 | Train Loss: 0.00081 | Train Acc: 0.983 | Val Acc: 0.970\n",
      "No Improvement: 7\n",
      "Epoch: 21/1000 | Train Loss: 0.00076 | Train Acc: 0.985 | Val Acc: 0.973\n",
      "Saving Best Model. Test Accuracy: 0.9265\n",
      "Epoch: 22/1000 | Train Loss: 0.00075 | Train Acc: 0.985 | Val Acc: 0.974\n",
      "Saving Best Model. Test Accuracy: 0.9272\n",
      "Epoch: 23/1000 | Train Loss: 0.00068 | Train Acc: 0.986 | Val Acc: 0.974\n",
      "No Improvement: 1\n",
      "Epoch: 24/1000 | Train Loss: 0.00063 | Train Acc: 0.987 | Val Acc: 0.974\n",
      "No Improvement: 2\n",
      "Epoch: 25/1000 | Train Loss: 0.00060 | Train Acc: 0.988 | Val Acc: 0.972\n",
      "No Improvement: 3\n",
      "Epoch: 26/1000 | Train Loss: 0.00064 | Train Acc: 0.987 | Val Acc: 0.971\n",
      "No Improvement: 4\n",
      "Epoch: 27/1000 | Train Loss: 0.00060 | Train Acc: 0.988 | Val Acc: 0.972\n",
      "No Improvement: 5\n",
      "Epoch: 28/1000 | Train Loss: 0.00055 | Train Acc: 0.989 | Val Acc: 0.973\n",
      "No Improvement: 6\n",
      "Epoch: 29/1000 | Train Loss: 0.00055 | Train Acc: 0.989 | Val Acc: 0.972\n",
      "No Improvement: 7\n",
      "Epoch: 30/1000 | Train Loss: 0.00049 | Train Acc: 0.990 | Val Acc: 0.975\n",
      "Saving Best Model. Test Accuracy: 0.9236\n",
      "Epoch: 31/1000 | Train Loss: 0.00053 | Train Acc: 0.989 | Val Acc: 0.973\n",
      "No Improvement: 1\n",
      "Epoch: 32/1000 | Train Loss: 0.00047 | Train Acc: 0.990 | Val Acc: 0.973\n",
      "No Improvement: 2\n",
      "Epoch: 33/1000 | Train Loss: 0.00046 | Train Acc: 0.991 | Val Acc: 0.970\n",
      "No Improvement: 3\n",
      "Epoch: 34/1000 | Train Loss: 0.00046 | Train Acc: 0.991 | Val Acc: 0.974\n",
      "No Improvement: 4\n",
      "Epoch: 35/1000 | Train Loss: 0.00044 | Train Acc: 0.991 | Val Acc: 0.973\n",
      "No Improvement: 5\n",
      "Epoch: 36/1000 | Train Loss: 0.00043 | Train Acc: 0.992 | Val Acc: 0.972\n",
      "No Improvement: 6\n",
      "Epoch: 37/1000 | Train Loss: 0.00042 | Train Acc: 0.992 | Val Acc: 0.975\n",
      "No Improvement: 7\n",
      "Epoch: 38/1000 | Train Loss: 0.00042 | Train Acc: 0.992 | Val Acc: 0.974\n",
      "No Improvement: 8\n",
      "Epoch: 39/1000 | Train Loss: 0.00041 | Train Acc: 0.992 | Val Acc: 0.973\n",
      "No Improvement: 9\n",
      "Epoch: 40/1000 | Train Loss: 0.00038 | Train Acc: 0.992 | Val Acc: 0.975\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00404 | Train Acc: 0.926 | Val Acc: 0.953\n",
      "Saving Best Model. Test Accuracy: 0.8809\n",
      "Epoch: 1/1000 | Train Loss: 0.00310 | Train Acc: 0.942 | Val Acc: 0.956\n",
      "Saving Best Model. Test Accuracy: 0.8909\n",
      "Epoch: 2/1000 | Train Loss: 0.00283 | Train Acc: 0.946 | Val Acc: 0.963\n",
      "Saving Best Model. Test Accuracy: 0.9113\n",
      "Epoch: 3/1000 | Train Loss: 0.00245 | Train Acc: 0.954 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.9019\n",
      "Epoch: 4/1000 | Train Loss: 0.00221 | Train Acc: 0.958 | Val Acc: 0.962\n",
      "No Improvement: 1\n",
      "Epoch: 5/1000 | Train Loss: 0.00195 | Train Acc: 0.963 | Val Acc: 0.968\n",
      "Saving Best Model. Test Accuracy: 0.9119\n",
      "Epoch: 6/1000 | Train Loss: 0.00198 | Train Acc: 0.963 | Val Acc: 0.964\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: 0.00181 | Train Acc: 0.966 | Val Acc: 0.967\n",
      "No Improvement: 2\n",
      "Epoch: 8/1000 | Train Loss: 0.00167 | Train Acc: 0.969 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9157\n",
      "Epoch: 9/1000 | Train Loss: 0.00156 | Train Acc: 0.970 | Val Acc: 0.971\n",
      "Saving Best Model. Test Accuracy: 0.9215\n",
      "Epoch: 10/1000 | Train Loss: 0.00150 | Train Acc: 0.972 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 11/1000 | Train Loss: 0.00142 | Train Acc: 0.972 | Val Acc: 0.970\n",
      "No Improvement: 2\n",
      "Epoch: 12/1000 | Train Loss: 0.00139 | Train Acc: 0.973 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 13/1000 | Train Loss: 0.00129 | Train Acc: 0.976 | Val Acc: 0.971\n",
      "No Improvement: 4\n",
      "Epoch: 14/1000 | Train Loss: 0.00119 | Train Acc: 0.977 | Val Acc: 0.971\n",
      "No Improvement: 5\n",
      "Epoch: 15/1000 | Train Loss: 0.00122 | Train Acc: 0.977 | Val Acc: 0.971\n",
      "No Improvement: 6\n",
      "Epoch: 16/1000 | Train Loss: 0.00114 | Train Acc: 0.979 | Val Acc: 0.970\n",
      "No Improvement: 7\n",
      "Epoch: 17/1000 | Train Loss: 0.00107 | Train Acc: 0.980 | Val Acc: 0.971\n",
      "No Improvement: 8\n",
      "Epoch: 18/1000 | Train Loss: 0.00103 | Train Acc: 0.980 | Val Acc: 0.971\n",
      "No Improvement: 9\n",
      "Epoch: 19/1000 | Train Loss: 0.00100 | Train Acc: 0.981 | Val Acc: 0.973\n",
      "Saving Best Model. Test Accuracy: 0.9223\n",
      "Epoch: 20/1000 | Train Loss: 0.00101 | Train Acc: 0.981 | Val Acc: 0.972\n",
      "No Improvement: 1\n",
      "Epoch: 21/1000 | Train Loss: 0.00085 | Train Acc: 0.984 | Val Acc: 0.971\n",
      "No Improvement: 2\n",
      "Epoch: 22/1000 | Train Loss: 0.00090 | Train Acc: 0.984 | Val Acc: 0.973\n",
      "No Improvement: 3\n",
      "Epoch: 23/1000 | Train Loss: 0.00091 | Train Acc: 0.983 | Val Acc: 0.972\n",
      "No Improvement: 4\n",
      "Epoch: 24/1000 | Train Loss: 0.00083 | Train Acc: 0.984 | Val Acc: 0.969\n",
      "No Improvement: 5\n",
      "Epoch: 25/1000 | Train Loss: 0.00080 | Train Acc: 0.985 | Val Acc: 0.971\n",
      "No Improvement: 6\n",
      "Epoch: 26/1000 | Train Loss: 0.00083 | Train Acc: 0.984 | Val Acc: 0.976\n",
      "Saving Best Model. Test Accuracy: 0.9329\n",
      "Epoch: 27/1000 | Train Loss: 0.00079 | Train Acc: 0.985 | Val Acc: 0.971\n",
      "No Improvement: 1\n",
      "Epoch: 28/1000 | Train Loss: 0.00078 | Train Acc: 0.986 | Val Acc: 0.974\n",
      "No Improvement: 2\n",
      "Epoch: 29/1000 | Train Loss: 0.00071 | Train Acc: 0.987 | Val Acc: 0.973\n",
      "No Improvement: 3\n",
      "Epoch: 30/1000 | Train Loss: 0.00078 | Train Acc: 0.985 | Val Acc: 0.975\n",
      "No Improvement: 4\n",
      "Epoch: 31/1000 | Train Loss: 0.00067 | Train Acc: 0.987 | Val Acc: 0.973\n",
      "No Improvement: 5\n",
      "Epoch: 32/1000 | Train Loss: 0.00070 | Train Acc: 0.988 | Val Acc: 0.973\n",
      "No Improvement: 6\n",
      "Epoch: 33/1000 | Train Loss: 0.00065 | Train Acc: 0.988 | Val Acc: 0.973\n",
      "No Improvement: 7\n",
      "Epoch: 34/1000 | Train Loss: 0.00067 | Train Acc: 0.987 | Val Acc: 0.975\n",
      "No Improvement: 8\n",
      "Epoch: 35/1000 | Train Loss: 0.00066 | Train Acc: 0.987 | Val Acc: 0.975\n",
      "No Improvement: 9\n",
      "Epoch: 36/1000 | Train Loss: 0.00065 | Train Acc: 0.987 | Val Acc: 0.973\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: 0.00889 | Train Acc: 0.848 | Val Acc: 0.933\n",
      "Saving Best Model. Test Accuracy: 0.8426\n",
      "Epoch: 1/1000 | Train Loss: 0.00753 | Train Acc: 0.867 | Val Acc: 0.945\n",
      "Saving Best Model. Test Accuracy: 0.8667\n",
      "Epoch: 2/1000 | Train Loss: 0.00668 | Train Acc: 0.884 | Val Acc: 0.946\n",
      "Saving Best Model. Test Accuracy: 0.8618\n",
      "Epoch: 3/1000 | Train Loss: 0.00640 | Train Acc: 0.892 | Val Acc: 0.949\n",
      "Saving Best Model. Test Accuracy: 0.8672\n",
      "Epoch: 4/1000 | Train Loss: 0.00641 | Train Acc: 0.891 | Val Acc: 0.958\n",
      "Saving Best Model. Test Accuracy: 0.8912\n",
      "Epoch: 5/1000 | Train Loss: 0.00589 | Train Acc: 0.900 | Val Acc: 0.961\n",
      "Saving Best Model. Test Accuracy: 0.8998\n",
      "Epoch: 6/1000 | Train Loss: 0.00568 | Train Acc: 0.904 | Val Acc: 0.961\n",
      "No Improvement: 1\n",
      "Epoch: 7/1000 | Train Loss: 0.00554 | Train Acc: 0.906 | Val Acc: 0.958\n",
      "No Improvement: 2\n",
      "Epoch: 8/1000 | Train Loss: 0.00545 | Train Acc: 0.906 | Val Acc: 0.957\n",
      "No Improvement: 3\n",
      "Epoch: 9/1000 | Train Loss: 0.00527 | Train Acc: 0.910 | Val Acc: 0.956\n",
      "No Improvement: 4\n",
      "Epoch: 10/1000 | Train Loss: 0.00501 | Train Acc: 0.914 | Val Acc: 0.964\n",
      "Saving Best Model. Test Accuracy: 0.9008\n",
      "Epoch: 11/1000 | Train Loss: 0.00482 | Train Acc: 0.917 | Val Acc: 0.962\n",
      "No Improvement: 1\n",
      "Epoch: 12/1000 | Train Loss: 0.00471 | Train Acc: 0.918 | Val Acc: 0.965\n",
      "Saving Best Model. Test Accuracy: 0.896\n",
      "Epoch: 13/1000 | Train Loss: 0.00456 | Train Acc: 0.921 | Val Acc: 0.962\n",
      "No Improvement: 1\n",
      "Epoch: 14/1000 | Train Loss: 0.00463 | Train Acc: 0.921 | Val Acc: 0.966\n",
      "Saving Best Model. Test Accuracy: 0.9107\n",
      "Epoch: 15/1000 | Train Loss: 0.00458 | Train Acc: 0.921 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9116\n",
      "Epoch: 16/1000 | Train Loss: 0.00451 | Train Acc: 0.923 | Val Acc: 0.968\n",
      "No Improvement: 1\n",
      "Epoch: 17/1000 | Train Loss: 0.00442 | Train Acc: 0.924 | Val Acc: 0.969\n",
      "No Improvement: 2\n",
      "Epoch: 18/1000 | Train Loss: 0.00410 | Train Acc: 0.930 | Val Acc: 0.968\n",
      "No Improvement: 3\n",
      "Epoch: 19/1000 | Train Loss: 0.00423 | Train Acc: 0.929 | Val Acc: 0.965\n",
      "No Improvement: 4\n",
      "Epoch: 20/1000 | Train Loss: 0.00407 | Train Acc: 0.931 | Val Acc: 0.967\n",
      "No Improvement: 5\n",
      "Epoch: 21/1000 | Train Loss: 0.00402 | Train Acc: 0.932 | Val Acc: 0.968\n",
      "No Improvement: 6\n",
      "Epoch: 22/1000 | Train Loss: 0.00402 | Train Acc: 0.931 | Val Acc: 0.965\n",
      "No Improvement: 7\n",
      "Epoch: 23/1000 | Train Loss: 0.00429 | Train Acc: 0.929 | Val Acc: 0.972\n",
      "Saving Best Model. Test Accuracy: 0.9155\n",
      "Epoch: 24/1000 | Train Loss: 0.00390 | Train Acc: 0.935 | Val Acc: 0.966\n",
      "No Improvement: 1\n",
      "Epoch: 25/1000 | Train Loss: 0.00403 | Train Acc: 0.930 | Val Acc: 0.969\n",
      "No Improvement: 2\n",
      "Epoch: 26/1000 | Train Loss: 0.00385 | Train Acc: 0.932 | Val Acc: 0.969\n",
      "No Improvement: 3\n",
      "Epoch: 27/1000 | Train Loss: 0.00390 | Train Acc: 0.933 | Val Acc: 0.965\n",
      "No Improvement: 4\n",
      "Epoch: 28/1000 | Train Loss: 0.00366 | Train Acc: 0.936 | Val Acc: 0.968\n",
      "No Improvement: 5\n",
      "Epoch: 29/1000 | Train Loss: 0.00371 | Train Acc: 0.936 | Val Acc: 0.968\n",
      "No Improvement: 6\n",
      "Epoch: 30/1000 | Train Loss: 0.00377 | Train Acc: 0.934 | Val Acc: 0.970\n",
      "No Improvement: 7\n",
      "Epoch: 31/1000 | Train Loss: 0.00369 | Train Acc: 0.937 | Val Acc: 0.970\n",
      "No Improvement: 8\n",
      "Epoch: 32/1000 | Train Loss: 0.00358 | Train Acc: 0.939 | Val Acc: 0.967\n",
      "No Improvement: 9\n",
      "Epoch: 33/1000 | Train Loss: 0.00367 | Train Acc: 0.937 | Val Acc: 0.973\n",
      "Saving Best Model. Test Accuracy: 0.9205\n",
      "Epoch: 34/1000 | Train Loss: 0.00368 | Train Acc: 0.939 | Val Acc: 0.967\n",
      "No Improvement: 1\n",
      "Epoch: 35/1000 | Train Loss: 0.00365 | Train Acc: 0.940 | Val Acc: 0.971\n",
      "No Improvement: 2\n",
      "Epoch: 36/1000 | Train Loss: 0.00334 | Train Acc: 0.942 | Val Acc: 0.961\n",
      "No Improvement: 3\n",
      "Epoch: 37/1000 | Train Loss: 0.00350 | Train Acc: 0.940 | Val Acc: 0.970\n",
      "No Improvement: 4\n",
      "Epoch: 38/1000 | Train Loss: 0.00351 | Train Acc: 0.941 | Val Acc: 0.971\n",
      "No Improvement: 5\n",
      "Epoch: 39/1000 | Train Loss: 0.00326 | Train Acc: 0.945 | Val Acc: 0.963\n",
      "No Improvement: 6\n",
      "Epoch: 40/1000 | Train Loss: 0.00343 | Train Acc: 0.943 | Val Acc: 0.972\n",
      "No Improvement: 7\n",
      "Epoch: 41/1000 | Train Loss: 0.00316 | Train Acc: 0.947 | Val Acc: 0.971\n",
      "No Improvement: 8\n",
      "Epoch: 42/1000 | Train Loss: 0.00358 | Train Acc: 0.944 | Val Acc: 0.971\n",
      "No Improvement: 9\n",
      "Epoch: 43/1000 | Train Loss: 0.00332 | Train Acc: 0.945 | Val Acc: 0.971\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -0.53035 | Train Acc: 0.947 | Val Acc: 0.969\n",
      "Saving Best Model. Test Accuracy: 0.9216\n",
      "Epoch: 1/1000 | Train Loss: -1.32822 | Train Acc: 0.911 | Val Acc: 0.956\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -2.62641 | Train Acc: 0.880 | Val Acc: 0.952\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -4.41951 | Train Acc: 0.859 | Val Acc: 0.947\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -6.60582 | Train Acc: 0.837 | Val Acc: 0.938\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -9.23820 | Train Acc: 0.821 | Val Acc: 0.934\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -12.26462 | Train Acc: 0.802 | Val Acc: 0.931\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -15.69463 | Train Acc: 0.798 | Val Acc: 0.930\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -19.61165 | Train Acc: 0.798 | Val Acc: 0.931\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -23.93514 | Train Acc: 0.798 | Val Acc: 0.931\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -28.72945 | Train Acc: 0.789 | Val Acc: 0.924\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -64.66941 | Train Acc: 0.739 | Val Acc: 0.770\n",
      "Saving Best Model. Test Accuracy: 0.7203\n",
      "Epoch: 1/1000 | Train Loss: -185.10251 | Train Acc: 0.629 | Val Acc: 0.711\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -390.84827 | Train Acc: 0.469 | Val Acc: 0.565\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -672.81655 | Train Acc: 0.412 | Val Acc: 0.475\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -1025.42569 | Train Acc: 0.415 | Val Acc: 0.381\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -1438.12013 | Train Acc: 0.412 | Val Acc: 0.467\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -1902.51383 | Train Acc: 0.401 | Val Acc: 0.474\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -2424.74054 | Train Acc: 0.427 | Val Acc: 0.497\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -3006.29355 | Train Acc: 0.413 | Val Acc: 0.377\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -3643.39061 | Train Acc: 0.386 | Val Acc: 0.379\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -4322.46113 | Train Acc: 0.393 | Val Acc: 0.379\n",
      "No Improvement: 10\n",
      "Epoch: 0/1000 | Train Loss: -9265.03320 | Train Acc: 0.449 | Val Acc: 0.662\n",
      "Saving Best Model. Test Accuracy: 0.612\n",
      "Epoch: 1/1000 | Train Loss: -24141.65084 | Train Acc: 0.523 | Val Acc: 0.471\n",
      "No Improvement: 1\n",
      "Epoch: 2/1000 | Train Loss: -47559.46732 | Train Acc: 0.360 | Val Acc: 0.372\n",
      "No Improvement: 2\n",
      "Epoch: 3/1000 | Train Loss: -78816.81090 | Train Acc: 0.389 | Val Acc: 0.289\n",
      "No Improvement: 3\n",
      "Epoch: 4/1000 | Train Loss: -116924.72855 | Train Acc: 0.380 | Val Acc: 0.474\n",
      "No Improvement: 4\n",
      "Epoch: 5/1000 | Train Loss: -161767.24746 | Train Acc: 0.285 | Val Acc: 0.387\n",
      "No Improvement: 5\n",
      "Epoch: 6/1000 | Train Loss: -212771.36623 | Train Acc: 0.289 | Val Acc: 0.282\n",
      "No Improvement: 6\n",
      "Epoch: 7/1000 | Train Loss: -269545.55048 | Train Acc: 0.322 | Val Acc: 0.473\n",
      "No Improvement: 7\n",
      "Epoch: 8/1000 | Train Loss: -331767.57767 | Train Acc: 0.354 | Val Acc: 0.378\n",
      "No Improvement: 8\n",
      "Epoch: 9/1000 | Train Loss: -400637.59337 | Train Acc: 0.360 | Val Acc: 0.294\n",
      "No Improvement: 9\n",
      "Epoch: 10/1000 | Train Loss: -474889.87137 | Train Acc: 0.325 | Val Acc: 0.294\n",
      "No Improvement: 10\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "patience = 10\n",
    "\n",
    "models = [SmallMLP(), MediumMLP(), LargeMLP(), ExtraLargeMLP(), SuperLargeMLP()]\n",
    "model_names = [\"small\", \"medium\", \"large\", \"extra_large\", \"super_large\"]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "lr_names = ['3', '2', '1']\n",
    "loss_functions = [nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "loss_fn_names = ['ce', 'nll']\n",
    "\n",
    "\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for loss_fn, loss_fn_name in zip(loss_functions, loss_fn_names):\n",
    "        for lr, lr_name in zip(learning_rates, lr_names):\n",
    "\n",
    "            train_accuracies, train_losses = [], []\n",
    "            val_accuracies, val_losses = [], []\n",
    "\n",
    "            lowest_loss = 100000000.0\n",
    "            best_accuracy = -1000000.0\n",
    "            no_improvement_count = 0\n",
    "\n",
    "            model = model.to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            init_time = time.time()\n",
    "\n",
    "            model_file_name = \"mn_{}_loss_{}_lr_{}.pth\".format(model_name, loss_fn_name, lr_name)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "\n",
    "                train_acc, train_loss = train(model, optimizer, loss_fn)\n",
    "                train_accuracies.append(train_acc)\n",
    "                train_losses.append(train_loss)\n",
    "\n",
    "                val_acc, val_loss = evalution(model, val_loader, loss_fn)\n",
    "                val_accuracies.append(val_acc)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                print(\"Epoch: {}/{} | Train Loss: {:.5f} | Train Acc: {:.3f} | Val Acc: {:.3f}\".format(epoch, epochs, train_loss, train_acc, val_acc))\n",
    "\n",
    "                if round(best_accuracy, 3) < round(val_acc, 3):\n",
    "                    best_accuracy = val_acc\n",
    "                    no_improvement_count = 0\n",
    "                    test_acc, test_loss, all_preductions, all_labels = evalution(model, test_loader, loss_fn, type=\"test\")\n",
    "                    cnf_matrix = confusion_matrix(all_labels, all_preductions)\n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'train_acc': train_acc,\n",
    "                        'val_acc': val_acc,\n",
    "                        'test_acc': test_acc,\n",
    "                        'confusion_matrix': cnf_matrix,\n",
    "                        'time': str(time.time() - init_time),\n",
    "                        'model_state_dict': optimizer.state_dict(),\n",
    "                    }, model_file_name)\n",
    "\n",
    "                    print(\"Saving Best Model. Test Accuracy: {}\".format(test_acc))\n",
    "\n",
    "                    # Saving Metrics\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"train_acc\"), \"wb\") as file:\n",
    "                        pickle.dump(train_accuracies, file)\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"val_acc\"), \"wb\") as file:\n",
    "                        pickle.dump(val_accuracies, file)\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"train_loss\"), \"wb\") as file:\n",
    "                        pickle.dump(train_losses, file)\n",
    "                    with open(\"mn_{}_loss_{}_lr_{}_{}.pkl\".format(model_name, loss_fn_name, lr, \"val_loss\"), \"wb\") as file:\n",
    "                        pickle.dump(val_losses, file)\n",
    "                    \n",
    "                else:\n",
    "                    no_improvement_count += 1\n",
    "                    print(\"No Improvement: {}\".format(no_improvement_count))\n",
    "\n",
    "                if no_improvement_count == patience:\n",
    "                    break\n",
    "\n",
    "\n",
    "# test_acc, test_loss, all_preductions, all_labels = evalution(test_loader, \"test\")\n",
    "# print(confusion_matrix(all_labels, all_preductions))\n",
    "# print(\"Test Acc: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907: 239.03750133514404: ./models_data/mn_small_loss_ce_lr_3.pth\n",
      "0.7648: 92.50413155555725: ./models_data/mn_small_loss_ce_lr_2.pth\n",
      "0.1: 40.1468551158905: ./models_data/mn_small_loss_ce_lr_1.pth\n",
      "0.1: 10.18802785873413: ./models_data/mn_small_loss_nll_lr_3.pth\n",
      "0.1: 10.00380277633667: ./models_data/mn_small_loss_nll_lr_2.pth\n",
      "0.1: 10.079720497131348: ./models_data/mn_small_loss_nll_lr_1.pth\n",
      "0.9198: 156.51865410804749: ./models_data/mn_medium_loss_ce_lr_3.pth\n",
      "0.9149: 129.0325949192047: ./models_data/mn_medium_loss_ce_lr_2.pth\n",
      "0.9155: 357.6251542568207: ./models_data/mn_medium_loss_ce_lr_1.pth\n",
      "0.9169: 10.559376239776611: ./models_data/mn_medium_loss_nll_lr_3.pth\n",
      "0.7629: 10.597379207611084: ./models_data/mn_medium_loss_nll_lr_2.pth\n",
      "0.3891: 158.45071029663086: ./models_data/mn_medium_loss_nll_lr_1.pth\n",
      "0.9191: 208.81551218032837: ./models_data/mn_large_loss_ce_lr_3.pth\n",
      "0.9251: 172.7361433506012: ./models_data/mn_large_loss_ce_lr_2.pth\n",
      "0.9199: 230.94704818725586: ./models_data/mn_large_loss_ce_lr_1.pth\n",
      "0.9156: 10.875810861587524: ./models_data/mn_large_loss_nll_lr_3.pth\n",
      "0.7906: 48.94240045547485: ./models_data/mn_large_loss_nll_lr_2.pth\n",
      "0.4115: 41.195780754089355: ./models_data/mn_large_loss_nll_lr_1.pth\n",
      "0.9247: 469.42350244522095: ./models_data/mn_extra_large_loss_ce_lr_3.pth\n",
      "0.9268: 306.44332456588745: ./models_data/mn_extra_large_loss_ce_lr_2.pth\n",
      "0.9241: 419.135128736496: ./models_data/mn_extra_large_loss_ce_lr_1.pth\n",
      "0.9217: 11.244721412658691: ./models_data/mn_extra_large_loss_nll_lr_3.pth\n",
      "0.7841: 11.266693592071533: ./models_data/mn_extra_large_loss_nll_lr_2.pth\n",
      "0.5295: 42.60801911354065: ./models_data/mn_extra_large_loss_nll_lr_1.pth\n",
      "0.9236: 314.40751600265503: ./models_data/mn_super_large_loss_ce_lr_3.pth\n",
      "0.9329: 269.6496202945709: ./models_data/mn_super_large_loss_ce_lr_2.pth\n",
      "0.9205: 342.0197675228119: ./models_data/mn_super_large_loss_ce_lr_1.pth\n",
      "0.9216: 11.326773643493652: ./models_data/mn_super_large_loss_nll_lr_3.pth\n",
      "0.7203: 11.365754127502441: ./models_data/mn_super_large_loss_nll_lr_2.pth\n",
      "0.612: 11.275341749191284: ./models_data/mn_super_large_loss_nll_lr_1.pth\n"
     ]
    }
   ],
   "source": [
    "models = [SmallMLP(), MediumMLP(), LargeMLP(), ExtraLargeMLP(), SuperLargeMLP()]\n",
    "model_names = [\"small\", \"medium\", \"large\", \"extra_large\", \"super_large\"]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "lr_names = ['3', '2', '1']\n",
    "loss_functions = [nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "loss_fn_names = ['ce', 'nll']\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for loss_fn, loss_fn_name in zip(loss_functions, loss_fn_names):\n",
    "        for lr, lr_name in zip(learning_rates, lr_names):\n",
    "            \n",
    "            model_file_name = \"./models_data/mn_{}_loss_{}_lr_{}.pth\".format(model_name, loss_fn_name, lr_name)\n",
    "            model = torch.load(model_file_name)\n",
    "            print(\"{}: {}: {}\".format(model['test_acc'], model['time'], model_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SuperLargeMLP()\n",
    "model_file_name = \"./models_data/mn_{}_loss_{}_lr_{}.pth\".format(\"super_large\", 'ce', 2)\n",
    "model = torch.load(model_file_name)\n",
    "\n",
    "cnf_matrix = model['confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [f\"Class {i}\" for i in range(1, 11)]\n",
    "confusion_df = pd.DataFrame(cnf_matrix, index=labels, columns=labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_df, annot=True, fmt='g', cmap='Blues', cbar=True, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"./models_data/mn_{}_loss_{}_lr_{}_{}.pkl\".format(\"super_large\", 'ce', 0.01, \"train_acc\"), \"rb\") as file:\n",
    "    train_acc = pickle.load(file)\n",
    "with open(\"./models_data/mn_{}_loss_{}_lr_{}_{}.pkl\".format(\"super_large\", 'ce', 0.01, \"train_loss\"), \"rb\") as file:\n",
    "    train_loss = pickle.load(file)\n",
    "with open(\"./models_data/mn_{}_loss_{}_lr_{}_{}.pkl\".format(\"super_large\", 'ce', 0.01, \"val_acc\"), \"rb\") as file:\n",
    "    val_acc = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(len(train_acc))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, train_loss, label=\"Train Loss\", color=\"blue\")\n",
    "plt.plot(epochs, train_acc, label=\"Train Accuracy\", color=\"green\")\n",
    "plt.plot(epochs, val_acc, label=\"Validation Accuracy\", color=\"orange\")\n",
    "\n",
    "plt.title(\"MLP Metrics Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss & Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
